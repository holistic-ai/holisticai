{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from holisticai.datasets import load_adult\n",
    "from holisticai.explainability import Explainer\n",
    "from holisticai.efficacy.metrics import classification_efficacy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.datasets import load_adult\n",
    "\n",
    "# Dataset\n",
    "dataset = load_adult()\n",
    "\n",
    "# Dataframe\n",
    "df = pd.concat([dataset[\"data\"], dataset[\"target\"]], axis=1)\n",
    "protected_variables = [\"sex\", \"race\"]\n",
    "output_variable = [\"class\"]\n",
    "\n",
    "# Simple preprocessing\n",
    "y = df[output_variable].replace({\">50K\": 1, \"<=50K\": 0})\n",
    "X = pd.get_dummies(df.drop(protected_variables + output_variable, axis=1))\n",
    "group = [\"sex\"]\n",
    "group_a = df[group] == \"Female\"\n",
    "group_b = df[group] == \"Male\"\n",
    "data = [X, y, group_a, group_b]\n",
    "\n",
    "# Train test split\n",
    "dataset = train_test_split(*data, test_size=0.2, shuffle=True)\n",
    "train_data = dataset[::2]\n",
    "test_data = dataset[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.hist(bins=10, figsize=(10, 10), color = 'mediumslateblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.bias.plots import correlation_matrix_plot\n",
    "\n",
    "correlation_matrix_plot(X, target_feature='age', size = (12,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "seed = np.random.seed(42) # set seed for reproducibility\n",
    "# simple preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed) # train test split\n",
    "\n",
    "\n",
    "model = GradientBoostingClassifier() # instantiate model\n",
    "model.fit(X_train, y_train) # fit model\n",
    "\n",
    "y_pred = model.predict(X_test) # compute predictions\n",
    "\n",
    "# compute efficacy metrics\n",
    "classification_efficacy_metrics(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Explainability Metrics (based on Permutation Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation feature importance\n",
    "permutation_explainer = Explainer(based_on='feature_importance',\n",
    "                      strategy_type='permutation',\n",
    "                      model_type='binary_classification',\n",
    "                      model = model, \n",
    "                      x = X, \n",
    "                      y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m permutation_explainer\u001b[39m.\u001b[39;49mmetrics()\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/_explainers.py:58\u001b[0m, in \u001b[0;36mExplainer.metrics\u001b[0;34m(self, top_k, detailed)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39mtop_k: int\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    Number of features to select\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplainer_handler\u001b[39m.\u001b[39mget_topk(top_k)\n\u001b[0;32m---> 58\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplainer_handler\u001b[39m.\u001b[39;49mmetrics(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams, detailed\u001b[39m=\u001b[39;49mdetailed)\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/metrics/feature_importance/extractors/permutation_feature_importance.py:153\u001b[0m, in \u001b[0;36mPermutationFeatureImportance.metrics\u001b[0;34m(self, feature_importance, conditional_feature_importance, detailed)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmetrics\u001b[39m(\u001b[39mself\u001b[39m, feature_importance, conditional_feature_importance, detailed):\n\u001b[1;32m    113\u001b[0m     reference_values \u001b[39m=\u001b[39m {\n\u001b[1;32m    114\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFourth Fifths\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mImportance Spread Divergence\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGlobal Explainability Ease Score\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[1;32m    137\u001b[0m     }\n\u001b[1;32m    139\u001b[0m     metrics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(\n\u001b[1;32m    140\u001b[0m         [\n\u001b[1;32m    141\u001b[0m             fourth_fifths(feature_importance),\n\u001b[1;32m    142\u001b[0m             importance_spread_divergence(feature_importance),\n\u001b[1;32m    143\u001b[0m             importance_spread_ratio(feature_importance),\n\u001b[1;32m    144\u001b[0m             global_overlap_score(\n\u001b[1;32m    145\u001b[0m                 feature_importance, conditional_feature_importance, detailed\n\u001b[1;32m    146\u001b[0m             ),\n\u001b[1;32m    147\u001b[0m             global_range_overlap_score(\n\u001b[1;32m    148\u001b[0m                 feature_importance, conditional_feature_importance, detailed\n\u001b[1;32m    149\u001b[0m             ),\n\u001b[1;32m    150\u001b[0m             global_similarity_score(\n\u001b[1;32m    151\u001b[0m                 feature_importance, conditional_feature_importance, detailed\n\u001b[1;32m    152\u001b[0m             ),\n\u001b[0;32m--> 153\u001b[0m             global_explainability_ease_score(\n\u001b[1;32m    154\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my, feature_importance\n\u001b[1;32m    155\u001b[0m             ),\n\u001b[1;32m    156\u001b[0m         ],\n\u001b[1;32m    157\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    160\u001b[0m     reference_column \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m    161\u001b[0m         [reference_values\u001b[39m.\u001b[39mget(metric) \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics\u001b[39m.\u001b[39mindex],\n\u001b[1;32m    162\u001b[0m         columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mReference\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    163\u001b[0m     )\u001b[39m.\u001b[39mset_index(metrics\u001b[39m.\u001b[39mindex)\n\u001b[1;32m    164\u001b[0m     metrics_with_reference \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([metrics, reference_column], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/metrics/feature_importance/global_importance/_global_metrics.py:63\u001b[0m, in \u001b[0;36mglobal_explainability_ease_score\u001b[0;34m(model_type, model, x, y, feature_importance)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mglobal_explainability_ease_score\u001b[39m(model_type, model, x, y, feature_importance):\n\u001b[0;32m---> 63\u001b[0m     exp_score \u001b[39m=\u001b[39m explainability_ease_score(model_type, model, x, y, feature_importance)\n\u001b[1;32m     64\u001b[0m     \u001b[39mreturn\u001b[39;00m exp_score\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/metrics/feature_importance/global_importance/_explainability_level.py:99\u001b[0m, in \u001b[0;36mexplainability_ease_score\u001b[0;34m(model_type, model, x, target, feature_importance)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary_classification\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     97\u001b[0m     targets \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(model\u001b[39m.\u001b[39mclasses_) \u001b[39m-\u001b[39m {\u001b[39m0\u001b[39m})\n\u001b[1;32m     98\u001b[0m     result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(\n\u001b[0;32m---> 99\u001b[0m         {\n\u001b[1;32m    100\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mGlobal Explainability Ease Score\u001b[39m\u001b[39m\"\u001b[39m: compute_partial_dependence(\n\u001b[1;32m    101\u001b[0m                 model, feature_importance, x, target\n\u001b[1;32m    102\u001b[0m             )\n\u001b[1;32m    103\u001b[0m             \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m targets\n\u001b[1;32m    104\u001b[0m         },\n\u001b[1;32m    105\u001b[0m         orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[39melif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    109\u001b[0m     result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(\n\u001b[1;32m    110\u001b[0m         {\n\u001b[1;32m    111\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mGlobal Explainability Ease Score\u001b[39m\u001b[39m\"\u001b[39m: compute_partial_dependence(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/metrics/feature_importance/global_importance/_explainability_level.py:100\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary_classification\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     97\u001b[0m     targets \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(model\u001b[39m.\u001b[39mclasses_) \u001b[39m-\u001b[39m {\u001b[39m0\u001b[39m})\n\u001b[1;32m     98\u001b[0m     result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(\n\u001b[1;32m     99\u001b[0m         {\n\u001b[0;32m--> 100\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mGlobal Explainability Ease Score\u001b[39m\u001b[39m\"\u001b[39m: compute_partial_dependence(\n\u001b[1;32m    101\u001b[0m                 model, feature_importance, x, target\n\u001b[1;32m    102\u001b[0m             )\n\u001b[1;32m    103\u001b[0m             \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m targets\n\u001b[1;32m    104\u001b[0m         },\n\u001b[1;32m    105\u001b[0m         orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    108\u001b[0m \u001b[39melif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    109\u001b[0m     result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(\n\u001b[1;32m    110\u001b[0m         {\n\u001b[1;32m    111\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mGlobal Explainability Ease Score\u001b[39m\u001b[39m\"\u001b[39m: compute_partial_dependence(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m         orient\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/metrics/feature_importance/global_importance/_explainability_level.py:59\u001b[0m, in \u001b[0;36mcompute_partial_dependence\u001b[0;34m(model, feature_importance, x, target)\u001b[0m\n\u001b[1;32m     55\u001b[0m categories \u001b[39m=\u001b[39m class_to_index\u001b[39m.\u001b[39mkeys()\n\u001b[1;32m     57\u001b[0m feature_importance_indexes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(feature_importance[\u001b[39m\"\u001b[39m\u001b[39mVariable\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mindex)\n\u001b[0;32m---> 59\u001b[0m partial_dependence \u001b[39m=\u001b[39m partial_dependence_creator(\n\u001b[1;32m     60\u001b[0m     model,\n\u001b[1;32m     61\u001b[0m     grid_resolution\u001b[39m=\u001b[39;49mgrid_resolution,\n\u001b[1;32m     62\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m     63\u001b[0m     feature_ids\u001b[39m=\u001b[39;49mfeature_importance_indexes,\n\u001b[1;32m     64\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[1;32m     67\u001b[0m     feat: compute_similarity(df, num_chunks)\n\u001b[1;32m     68\u001b[0m     \u001b[39mfor\u001b[39;00m feat, df \u001b[39min\u001b[39;00m partial_dependence\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     69\u001b[0m }\n\u001b[1;32m     70\u001b[0m score_data \u001b[39m=\u001b[39m compute_feature_scores(data, threshold)\n",
      "File \u001b[0;32m/mnt/c/Users/cris_/Downloads/holisticai-20230918T071212Z-001/holisticai/tutorials/explainability/../../holisticai/explainability/metrics/feature_importance/utils.py:215\u001b[0m, in \u001b[0;36mpartial_dependence_creator\u001b[0;34m(model, grid_resolution, x, feature_ids, target)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     kargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mpercentiles\u001b[39m\u001b[39m\"\u001b[39m: percentiles})\n\u001b[0;32m--> 215\u001b[0m g \u001b[39m=\u001b[39m PartialDependenceDisplay\u001b[39m.\u001b[39;49mfrom_estimator(model, \n\u001b[1;32m    216\u001b[0m                                             x, \n\u001b[1;32m    217\u001b[0m                                             feature_ids, \n\u001b[1;32m    218\u001b[0m                                             feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    219\u001b[0m                                             percentiles\u001b[39m=\u001b[39;49mpercentiles,\n\u001b[1;32m    220\u001b[0m                                             response_method\u001b[39m=\u001b[39;49mresponse_method, \n\u001b[1;32m    221\u001b[0m                                             method\u001b[39m=\u001b[39;49mmethod, \n\u001b[1;32m    222\u001b[0m                                             grid_resolution\u001b[39m=\u001b[39;49mgrid_resolution) \n\u001b[1;32m    223\u001b[0m plt\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    224\u001b[0m g \u001b[39m=\u001b[39m PartialDependenceDisplay\u001b[39m.\u001b[39mfrom_estimator(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/inspection/_plot/partial_dependence.py:704\u001b[0m, in \u001b[0;36mPartialDependenceDisplay.from_estimator\u001b[0;34m(cls, estimator, X, features, categorical_features, feature_names, target, response_method, n_cols, grid_resolution, percentiles, method, n_jobs, verbose, line_kw, ice_lines_kw, pd_line_kw, contour_kw, ax, kind, centered, subsample, random_state)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWhen a floating-point, subsample=\u001b[39m\u001b[39m{\u001b[39;00msubsample\u001b[39m}\u001b[39;00m\u001b[39m should be in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe (0, 1) range.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m         )\n\u001b[1;32m    703\u001b[0m \u001b[39m# compute predictions and/or averaged predictions\u001b[39;00m\n\u001b[0;32m--> 704\u001b[0m pd_results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49mverbose)(\n\u001b[1;32m    705\u001b[0m     delayed(partial_dependence)(\n\u001b[1;32m    706\u001b[0m         estimator,\n\u001b[1;32m    707\u001b[0m         X,\n\u001b[1;32m    708\u001b[0m         fxs,\n\u001b[1;32m    709\u001b[0m         feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    710\u001b[0m         categorical_features\u001b[39m=\u001b[39;49mcategorical_features,\n\u001b[1;32m    711\u001b[0m         response_method\u001b[39m=\u001b[39;49mresponse_method,\n\u001b[1;32m    712\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    713\u001b[0m         grid_resolution\u001b[39m=\u001b[39;49mgrid_resolution,\n\u001b[1;32m    714\u001b[0m         percentiles\u001b[39m=\u001b[39;49mpercentiles,\n\u001b[1;32m    715\u001b[0m         kind\u001b[39m=\u001b[39;49mkind_plot,\n\u001b[1;32m    716\u001b[0m     )\n\u001b[1;32m    717\u001b[0m     \u001b[39mfor\u001b[39;49;00m kind_plot, fxs \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(kind_, features)\n\u001b[1;32m    718\u001b[0m )\n\u001b[1;32m    720\u001b[0m \u001b[39m# For multioutput regression, we can only check the validity of target\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[39m# now that we have the predictions.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[39m# Also note: as multiclass-multioutput classifiers are not supported,\u001b[39;00m\n\u001b[1;32m    723\u001b[0m \u001b[39m# multiclass and multioutput scenario are mutually exclusive. So there is\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[39m# no risk of overwriting target_idx here.\u001b[39;00m\n\u001b[1;32m    725\u001b[0m pd_result \u001b[39m=\u001b[39m pd_results[\u001b[39m0\u001b[39m]  \u001b[39m# checking the first result is enough\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/inspection/_partial_dependence.py:543\u001b[0m, in \u001b[0;36mpartial_dependence\u001b[0;34m(estimator, X, features, categorical_features, feature_names, response_method, percentiles, grid_resolution, method, kind)\u001b[0m\n\u001b[1;32m    535\u001b[0m grid, values \u001b[39m=\u001b[39m _grid_from_X(\n\u001b[1;32m    536\u001b[0m     _safe_indexing(X, features_indices, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    537\u001b[0m     percentiles,\n\u001b[1;32m    538\u001b[0m     is_categorical,\n\u001b[1;32m    539\u001b[0m     grid_resolution,\n\u001b[1;32m    540\u001b[0m )\n\u001b[1;32m    542\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbrute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 543\u001b[0m     averaged_predictions, predictions \u001b[39m=\u001b[39m _partial_dependence_brute(\n\u001b[1;32m    544\u001b[0m         estimator, grid, features_indices, X, response_method\n\u001b[1;32m    545\u001b[0m     )\n\u001b[1;32m    547\u001b[0m     \u001b[39m# reshape predictions to\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[39m# (n_outputs, n_instances, n_values_feature_0, n_values_feature_1, ...)\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     predictions \u001b[39m=\u001b[39m predictions\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    550\u001b[0m         \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m[val\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m values]\n\u001b[1;32m    551\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/inspection/_partial_dependence.py:184\u001b[0m, in \u001b[0;36m_partial_dependence_brute\u001b[0;34m(est, grid, features, X, response_method)\u001b[0m\n\u001b[1;32m    175\u001b[0m     _safe_assign(X_eval, new_values[i], column_indexer\u001b[39m=\u001b[39mvariable)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[39m# Note: predictions is of shape\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39m# (n_points,) for non-multioutput regressors\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[39m# (n_points, 2) for binary classification\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[39m# (n_points, n_classes) for multiclass classification\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     pred \u001b[39m=\u001b[39m prediction_method(X_eval)\n\u001b[1;32m    186\u001b[0m     predictions\u001b[39m.\u001b[39mappend(pred)\n\u001b[1;32m    187\u001b[0m     \u001b[39m# average over samples\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:1355\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1335\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict class probabilities for X.\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \n\u001b[1;32m   1337\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[39m        If the ``loss`` does not support probabilities.\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m   1356\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1357\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss\u001b[39m.\u001b[39m_raw_prediction_to_proba(raw_predictions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_gb.py:1261\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1243\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \n\u001b[1;32m   1245\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[39m        array of shape (n_samples,).\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1261\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1262\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1263\u001b[0m     )\n\u001b[1;32m   1264\u001b[0m     raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\n\u001b[1;32m   1265\u001b[0m     \u001b[39mif\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "permutation_explainer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_explainer.partial_dependence_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_explainer.metrics(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast Whole Importance vs. Group Importance\n",
    "# -> Order -> mean positions\n",
    "# -> Range -> match range of position \n",
    "# -> Similarity -> compute similarity\n",
    "# -> e.g. we can see that Q0-Q1 and Q2-Q3 strong changes in their position but their importance weights maintains a high similarity with the whole model.\n",
    "# -> e.g. we can see that Q1-Q2 and Q3-Q4 small changes in their position and their importance weights maintains a high similarity with the whole model.\n",
    "permutation_explainer.contrast_visualization(show_connections=False)\n",
    "# TODO separate show connections sin a second matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_explainer.bar_plot(max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_explainer.feature_importance_table(sorted_by='Global', top_n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Explainability metrics (based on Surrogate Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate feature importance\n",
    "surrogate_explainer = Explainer(based_on='feature_importance',\n",
    "                      strategy_type='surrogate',\n",
    "                      model_type='regression',\n",
    "                      model = model, \n",
    "                      x = X, \n",
    "                      y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax=plt.subplots(figsize=(15,5))\n",
    "surrogate_explainer.partial_dependence_plot(ax=ax, kind=\"both\") # kind: [individual,average,both]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer.bar_plot(max_display=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer.feature_importance_table(sorted_by='Global', top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(15,3))\n",
    "_ = surrogate_explainer.tree_visualization('sklearn', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_explainer.tree_visualization('graphviz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = surrogate_explainer.tree_visualization('dtreeviz', scale=2)\n",
    "vis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Explainability Metrics (based on Lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime feature importance\n",
    "lime_explainer = Explainer(based_on='feature_importance',\n",
    "                      strategy_type='lime',\n",
    "                      model_type='regression',\n",
    "                      model = model, \n",
    "                      x = X, \n",
    "                      y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer.metrics(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer.bar_plot(max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer.show_importance_stability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer.show_data_stability_boundaries(top_n=10, figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explainer.show_features_stability_boundaries(figsize=(15,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
