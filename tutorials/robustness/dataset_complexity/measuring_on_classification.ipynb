{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### **A Metric to Explicitly Tell You When to Retrain a Machine Learning Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog: link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Application on Sintetic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "from holisticai.robustness.metrics.dataset_complexity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sintetic datasets\n",
    "\n",
    "dataset_generators = [\n",
    "    (\"Make Moons\", generate_moons),\n",
    "    # (\"Make Circles\", generate_circles),\n",
    "    # (\"Make Classification\", generate_classification),\n",
    "    # (\"Make Blobs\", generate_blobs),\n",
    "    # (\"XOR\", generate_xor),\n",
    "    # (\"Swiss Roll\", generate_swiss_roll),\n",
    "    # (\"Gaussian Quantiles\", generate_gaussian_quantiles),\n",
    "    # (\"Make Friedman 1\", generate_friedman1),\n",
    "    # (\"Spirals\", generate_spirals),\n",
    "    (\"Two Intertwined Spirals\", generate_two_intertwined_spirals)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate MAGOC on the datasets\n",
    "evaluate_datasets(dataset_generators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Application on Real datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from holisticai.robustness.metrics.dataset_complexity import *\n",
    "from holisticai.datasets import load_dataset\n",
    "\n",
    "# List of datasets\n",
    "datasets = [\n",
    "    \"adult\",\n",
    "    # \"law_school\",\n",
    "    # \"student_multiclass\",\n",
    "    # \"us_crime_multiclass\",\n",
    "    # \"clinical_records\",\n",
    "    # # New datasets\n",
    "    # \"german_credit\",\n",
    "    # \"census_kdd\",\n",
    "    # \"bank_marketing\",\n",
    "    # \"compass\",\n",
    "    # \"diabetes\",\n",
    "    # \"acsincome\",\n",
    "    \"acspublic\"\n",
    "]\n",
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Linear Discriminant Analysis\": LinearDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store complexities and accuracies\n",
    "complexities_data = {}\n",
    "accuracies_data = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    try:\n",
    "        # Load dataset\n",
    "        dataset = load_dataset(dataset_name)\n",
    "\n",
    "        # Shrink the dataset to a maximum of 1000 rows\n",
    "        n_rows = min(1000, dataset[\"X\"].shape[0])\n",
    "        X = dataset[\"X\"].iloc[:n_rows, :]\n",
    "        y = dataset[\"y\"].iloc[:n_rows]\n",
    "\n",
    "        # Standardize the data\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "        # Split the dataset into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        # Initialize ComplexityCalculator\n",
    "        cc = px.ComplexityCalculator()\n",
    "\n",
    "        # Fit ComplexityCalculator with data\n",
    "        cc.fit(X, y)\n",
    "\n",
    "        # Extract complexities from the report\n",
    "        complexities = cc.report()[\"complexities\"]\n",
    "        complexities_data[dataset_name] = complexities\n",
    "\n",
    "        # Evaluate models on the dataset\n",
    "        for model_name, model in models.items():\n",
    "            try:\n",
    "                # Train the model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Predict on the test set\n",
    "                y_pred = model.predict(X_test)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "                # Append accuracy for the model and dataset\n",
    "                accuracies_data[model_name].append(accuracy)\n",
    "            except Exception as e:\n",
    "                # Append NaN if the model fails\n",
    "                accuracies_data[model_name].append(float(\"nan\"))\n",
    "                print(f\"Error with model {model_name} on dataset {dataset_name}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle dataset loading or processing errors\n",
    "        print(f\"Error processing dataset {dataset_name}: {e}\")\n",
    "        for model_name in models.keys():\n",
    "            accuracies_data[model_name].append(float(\"nan\"))\n",
    "\n",
    "# Convert the complexities data into a DataFrame\n",
    "complexities_df = pd.DataFrame(complexities_data)\n",
    "\n",
    "# Convert the accuracies data into a DataFrame\n",
    "accuracies_df = pd.DataFrame(accuracies_data, index=datasets).T\n",
    "\n",
    "# Display the DataFrames\n",
    "display(\"Accuracies DataFrame:\")\n",
    "display(accuracies_df)\n",
    "\n",
    "# Extract the `t1` row from `complexities_df`\n",
    "t1_series = complexities_df.loc[\"t1\"]  # Extract t1 values for each dataset\n",
    "\n",
    "# Divide accuracies_df by the T1\n",
    "src_df = accuracies_df.div(t1_series, axis=1)\n",
    "\n",
    "# MAGOC dataframe\n",
    "print(\"The MAGOC metric by model and dataset:\\n(values below 1.0 indicate that retraining the model on the dataset, if needed, is NOT recommended)\")\n",
    "display(src_df.dropna(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
