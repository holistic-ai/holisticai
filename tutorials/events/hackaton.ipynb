{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "<img src=\"https://static.propublica.org/projects/algorithmic-bias/assets/img/generated/opener-b-crop-1200*675-00796e.jpg\" width=\"400\">\n",
    "<br>Study Case: The COMPAS Dataset\n",
    "<h4 align=\"center\">Technical Risks in Machine Learning Models</h2>\n",
    "</h1>\n",
    "\n",
    "\n",
    "The COMPAS dataset is a dataset that includes criminal records and demographic information of individuals assessed by the [COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)](https://doc.wi.gov/Pages/AboutDOC/COMPAS.aspx) risk assessment tool. The data contains information on individuals' criminal history, recidivism, and demographic attributes, which has been widely analyzed to evaluate the fairness and accuracy of risk assessments. This dataset has been utilized in studies focused on bias detection and mitigation in machine learning, especially regarding racial biases in predictive policing.\n",
    "\n",
    "**(Goal)** The primary goal of working with the COMPAS dataset is to evaluate and mitigate potential biases within predictive models used for assessing recidivism risk. By analyzing the dataset, the aim is to determine whether the modelâ€™s predictions are influenced by sensitive attributes like race, gender, and age, and to develop techniques to promote fairness. This includes the exploration of various bias mitigation algorithms, such as pre-processing, in-processing, and post-processing approaches, with a particular emphasis on maintaining predictive accuracy while enhancing the equity of model outcomes.\n",
    "\n",
    "**(Features)** The following table presents the 16 features of Compas dataset, inclusing the target variable  \"two_year_recid\".\n",
    "\n",
    "\n",
    "| Feature                  | Description                                                                                      |\n",
    "|--------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| `age`                    | Age of the individual at the time of the assessment.                                             |\n",
    "| `c_charge_degree`        | Degree of the charge (e.g., 'M' for misdemeanor, 'F' for felony).                                |\n",
    "| `race`                   | Race of the individual (e.g., African-American, Caucasian).                                      |\n",
    "| `age_cat`                | Categorical age group (e.g., 'Less than 25', '25 - 45', 'Greater than 45').                      |\n",
    "| `score_text`             | Risk level as categorized by COMPAS (e.g., 'Low', 'Medium', 'High').                             |\n",
    "| `sex`                    | Gender of the individual (e.g., Male, Female).                                                   |\n",
    "| `priors_count`           | Number of prior offenses committed by the individual.                                            |\n",
    "| `days_b_screening_arrest`| Days between arrest and screening date.                                                          |\n",
    "| `decile_score`           | COMPAS risk score on a scale from 1 to 10.                                                       |\n",
    "| `juv_fel_count`          | Count of juvenile felony offenses.                                                               |\n",
    "| `juv_misd_count`         | Count of juvenile misdemeanor offenses.                                                          |\n",
    "| `juv_other_count`        | Count of other juvenile offenses.                                                                |\n",
    "| `v_type_of_assessment`   | Type of assessment for violent recidivism risk (e.g., 'Risk of Violence').                      |\n",
    "| `c_days_from_compas`     | Days since the COMPAS assessment was completed.                                                  |\n",
    "| `v_score_text`           | Categorical violent risk level as assessed by COMPAS (e.g., 'Low', 'Medium', 'High').           |\n",
    "| `v_decile_score`         | COMPAS decile score specific to violent recidivism risk.                                         |\n",
    "| `(target) two_year_recid`      | Binary indicator of whether the individual was rearrested within two years of the screening date.     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"compas_two_year_recid\", protected_attribute=\"sex\")\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, random_state=42)\n",
    "train = split_dataset['train']\n",
    "test = split_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train a Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from holisticai.utils import BinaryClassificationProxy\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(train['X'], train['y'])\n",
    "\n",
    "proxy = BinaryClassificationProxy(predict=model.predict, predict_proba=model.predict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measuring Efficacy\n",
    "\n",
    "Efficacy metrics are used to evaluate the performance of a model by quantifying how accurately it makes predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Accuracy\n",
    "\n",
    "**Accuracy** is a metric that measures the proportion of correct predictions made by a classification model out of the total predictions. It is a commonly used metric for model evaluation, especially when the classes are balanced.\n",
    "\n",
    "### Formula\n",
    "\n",
    "Accuracy is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Predictions}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **True Positives (TP)**: Correct positive predictions.\n",
    "- **True Negatives (TN)**: Correct negative predictions.\n",
    "- **Total Predictions** $= \\text{True Positives} + \\text{True Negatives} + \\text{False Positives} + \\text{False Negatives}$.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Accuracy = 1**: The model predicts all outcomes correctly.\n",
    "- **Accuracy < 1**: The model has some incorrect predictions.\n",
    "\n",
    "Accuracy is useful when the class distribution is balanced. However, it can be misleading if the data is imbalanced, as it does no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6404858299595142"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = proxy.predict(test['X'])\n",
    "accuracy_score(test['y'], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) F1 Score\n",
    "\n",
    "The **F1 Score** is a metric that combines both precision and recall into a single score. It is especially useful for evaluating the performance of a classification model when there is an imbalance in the class distribution, as it balances the trade-off between false positives and false negatives.\n",
    "\n",
    "### Formula\n",
    "\n",
    "The F1 Score is the harmonic mean of precision and recall and is defined as:\n",
    "\n",
    "$$\n",
    "F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **Precision**: The ratio of correctly predicted positive observations to total predicted positives.\n",
    "\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "  $$\n",
    "\n",
    "- **Recall**: The ratio of correctly predicted positive observations to all actual positives.\n",
    "\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "  $$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **F1 Score = 1**: Perfect precision and recall.\n",
    "- **F1 Score = 0**: Model fails to identify any true positives.\n",
    "  \n",
    "A higher F1 Score indicates better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.587360594795539"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(test['y'], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What other efficacy metrics do we have for binary classification? Holistic AI library allows you to perform a practical inspection of the metrics by calling ```classification_efficacy_metrics```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.640486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.633962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.603053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.572464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.587361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value  Reference\n",
       "Metric                                \n",
       "Accuracy           0.640486          1\n",
       "Balanced Accuracy  0.633962          1\n",
       "Precision          0.603053          1\n",
       "Recall             0.572464          1\n",
       "F1-Score           0.587361          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.efficacy.metrics import classification_efficacy_metrics\n",
    "\n",
    "classification_efficacy_metrics(test['y'], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Measuring Bias\n",
    "\n",
    "In machine learning fairness, Equal Opportunity and Equal Outcomes are distinct concepts:\n",
    "\n",
    "- **Equal Opportunity**: Ensures individuals with similar qualifications have equal chances of positive outcomes, focusing on equal true positive rates across groups.\n",
    "\n",
    "- **Equal Outcomes**: Aims for equal proportions of positive results among different demographic groups, regardless of individual qualifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Disparate Impact\n",
    "\n",
    "**Disparate Impact** is a fairness metric used to measure the relative rate of favorable outcomes between an unprivileged group and a privileged group. It is commonly used to assess whether a modelâ€™s predictions disproportionately favor one group over another. A value close to 1 indicates fairness, while values significantly above or below 1 indicate potential bias.\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$\n",
    "\\text{Disparate Impact} = \\frac{P(\\text{positive outcome | unprivileged})}{P(\\text{positive outcome | privileged})}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $P(\\text{positive outcome | unprivileged})$ is the probability of a positive outcome for the unprivileged group.\n",
    "- $P(\\text{positive outcome | privileged})$ is the probability of a positive outcome for the privileged group.\n",
    "\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Disparate Impact â‰ˆ 1**: The model is fair (similar outcomes for both groups).\n",
    "- **< 1**: The privileged group has a higher rate of positive outcomes.\n",
    "- **> 1**: The unprivileged group has a higher rate of positive outcomes.\n",
    "\n",
    "In practice, a common threshold for fairness is that **Disparate Impact should be between 0.8 and 1.25**. If the metric falls outside this range, the model may be considered biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5133810207688907"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.bias.metrics import disparate_impact\n",
    "\n",
    "disparate_impact(test['group_a'], test['group_b'], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Equal Opportunity Difference\n",
    "\n",
    "The **Equal Opportunity Difference** is a fairness metric that measures the difference in true positive rates (TPR) between privileged and unprivileged groups in a classification model. Ideally, this difference should be close to zero to ensure fairness.\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$\n",
    "\\text{Equal Opportunity Difference} = TPR_{privileged} - TPR_{unprivileged}\n",
    "$$\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **0**: The model is fair (Equal Opportunity).\n",
    "- **Positive**: The privileged group has a higher chance of a positive prediction.\n",
    "- **Negative**: The unprivileged group has a higher chance of a positive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1722962503873567"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.bias.metrics import equal_opportunity_diff\n",
    "\n",
    "equal_opportunity_diff(test['group_a'], test['group_b'], y_test_pred, test['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access all bias metrics for binary classification available in the HolisticAI library using the ```classification_bias_metrics``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>0.154226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>1.513381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Fifths Rule</th>\n",
       "      <td>0.660772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohen D</th>\n",
       "      <td>0.314466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2SD Rule</th>\n",
       "      <td>4.359618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equality of Opportunity Difference</th>\n",
       "      <td>0.172296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Difference</th>\n",
       "      <td>0.103999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.138148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Difference</th>\n",
       "      <td>-0.006978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Value  Reference\n",
       "Metric                                                 \n",
       "Statistical Parity                  0.154226          0\n",
       "Disparate Impact                    1.513381          1\n",
       "Four Fifths Rule                    0.660772          1\n",
       "Cohen D                             0.314466          0\n",
       "2SD Rule                            4.359618          0\n",
       "Equality of Opportunity Difference  0.172296          0\n",
       "False Positive Rate Difference      0.103999          0\n",
       "Average Odds Difference             0.138148          0\n",
       "Accuracy Difference                -0.006978          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.bias.metrics import classification_bias_metrics\n",
    "\n",
    "classification_bias_metrics(test['group_a'], test['group_b'], y_test_pred, test['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Explainability\n",
    "\n",
    "Model interpretability can be quantified through various criteria that assess how understandable a model is, as well as through transparent surrogate models that aim to represent the actual model and its decision-making process. Some criteria include:\n",
    "\n",
    "- **Concentration of Feature Importance**: Evaluating how feature importance is distributed across the model.\n",
    "\n",
    "- **Consistency of Feature Importance Ranking**: Assessing the stability of feature importance rankings across different decision groups within the model, such as classes 0 and 1 in binary classification.\n",
    "\n",
    "- **Stability of Feature Importance Across the Dataset**: Analyzing how feature importance varies throughout the dataset.\n",
    "\n",
    "- **Complexity of Feature Relationships**: Examining the complexity of the relationship between features and their partial dependence plots.\n",
    "\n",
    "Another approach to quantifying interpretability is to evaluate how effectively a transparent model fits the actual model. For instance, if the surrogate model is a decision tree, additional measures such as tree depth or the number of features used by the transparent model can be considered.\n",
    "\n",
    "In this tutorial, we will calculate certain model features that will assist in evaluating interpretability metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holisticai.inspection import compute_permutation_importance\n",
    "from holisticai.utils.surrogate_models import create_surrogate_model\n",
    "from holisticai.inspection import compute_partial_dependence\n",
    "from holisticai.inspection import compute_conditional_permutation_importance\n",
    "\n",
    "\n",
    "# Feature Importance\n",
    "importance = compute_permutation_importance(proxy, X=train['X'], y=train['y'])\n",
    "top_importance = importance.top_alpha()\n",
    "top_feature_names = top_importance.feature_names\n",
    "\n",
    "# Conditional Feature Importance\n",
    "conditional_impotance = compute_conditional_permutation_importance(proxy, X=test['X'], y=test['y'])\n",
    "\n",
    "# Partial Dependence\n",
    "X_sample = test['X'].sample(1000)\n",
    "partial_dependence = compute_partial_dependence(features=top_feature_names, proxy=proxy, X=X_sample)\n",
    "\n",
    "# Surrogate Model\n",
    "surrogate_model = create_surrogate_model(X=train['X'], y_pred=train['y'], surrogate_type='tree', learning_task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring Alpha  Score that represents the percentage of features that represent the 80% of importnaces in the model behaivours. A lower value points that we can explain the model decision with few features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.explainability.metrics.global_feature_importance import alpha_score\n",
    "\n",
    "alpha_score(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring Fluctuation Ratio points the percentage in the PDP curve that present fluctuation in the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06685125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.explainability.metrics.global_feature_importance import fluctuation_ratio\n",
    "\n",
    "fluctuation_ratio(partial_dependence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank Alignment estima a porcentagem de features que permancem alineados no top of importances for label 0 and label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3653846153846154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.explainability.metrics.global_feature_importance import rank_alignment\n",
    "\n",
    "rank_alignment(conditional_impotance, top_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Feature Importance Based Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Spread Divergence</th>\n",
       "      <td>0.454325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fluctuation Ratio</th>\n",
       "      <td>0.066851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank Alignment</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha Score</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value Reference\n",
       "Spread Divergence  0.454325         1\n",
       "Fluctuation Ratio  0.066851         0\n",
       "Rank Alignment     0.428571         1\n",
       "Alpha Score             0.4         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.explainability.metrics import classification_global_feature_importance_explainability_metrics\n",
    "\n",
    "classification_global_feature_importance_explainability_metrics(partial_dependence, importance, conditional_impotance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree based Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weighted Average Depth</th>\n",
       "      <td>15.531976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted Average Explainability Score</th>\n",
       "      <td>11.207445</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted Gini Index</th>\n",
       "      <td>0.699632</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree Depth Variance</th>\n",
       "      <td>20.405185</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Rules</th>\n",
       "      <td>1352.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of Features</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             value  reference\n",
       "metric                                                       \n",
       "Weighted Average Depth                   15.531976        0.0\n",
       "Weighted Average Explainability Score    11.207445        0.0\n",
       "Weighted Gini Index                       0.699632        0.0\n",
       "Tree Depth Variance                      20.405185        0.0\n",
       "Number of Rules                        1352.000000        1.0\n",
       "Number of Features                       18.000000        1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.explainability.metrics import tree_explainability_metrics\n",
    "\n",
    "tree_explainability_metrics(surrogate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surrogate Based Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Degradation</th>\n",
       "      <td>0.049223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surrogate Fidelity</th>\n",
       "      <td>0.79919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surrogate Feature Stability</th>\n",
       "      <td>0.926316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Value Reference\n",
       "Accuracy Degradation         0.049223         0\n",
       "Surrogate Fidelity            0.79919         1\n",
       "Surrogate Feature Stability  0.926316         1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.explainability.metrics import classification_surrogate_explainability_metrics\n",
    "\n",
    "y_pred = proxy.predict(test['X'])\n",
    "classification_surrogate_explainability_metrics(test['X'], test['y'], y_pred, surrogate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Security metrics in machine learning evaluate the robustness and resilience of models against threats to data privacy, model integrity, and information leakage. They provide insight into how susceptible a model is to various risks and guide strategies to safeguard sensitive information and maintain reliable performance.\n",
    "\n",
    "Hereâ€™s a brief description of each type of security metric in the library:\n",
    "\n",
    "- **SHAPR**: This metric assesses membership privacy risk by estimating how much individual training data points influence model predictions. By using Shapley values, SHAPR quantifies the likelihood of data memorization, which can reveal vulnerabilities to membership inference attacks.\n",
    "\n",
    "- **Data Minimizer**: Similar to feature selection methods, Data Minimizer evaluates the modelâ€™s performance as features are iteratively removed. By identifying features that have minimal impact on model accuracy, it highlights areas where data minimization can improve privacy without sacrificing effectiveness.\n",
    "\n",
    "- **Privacy Risk Score**: This metric quantifies the risk of exposure for each data record within the model, typically by estimating the likelihood that an adversary could infer whether a specific record was part of the training data. Privacy Risk Score helps prioritize sensitive data points for potential mitigation strategies, ensuring that high-risk records are better protected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.1197602e-01, -7.8640449e-01,  1.2785778e-02, ...,\n",
       "         8.1012701e-04,  8.1012701e-04,  0.0000000e+00],\n",
       "       [ 8.3767611e-01, -7.6070446e-01,  3.8485873e-02, ...,\n",
       "         8.0971658e-04,  8.0971658e-04,  8.0971658e-04],\n",
       "       [ 8.3767611e-01, -7.6070446e-01,  3.8485873e-02, ...,\n",
       "         8.0971658e-04,  8.0971658e-04,  8.0971658e-04],\n",
       "       ...,\n",
       "       [ 8.1197602e-01, -7.8640449e-01,  1.2785778e-02, ...,\n",
       "         8.1012701e-04,  8.1012701e-04,  0.0000000e+00],\n",
       "       [-8.3686644e-01,  7.6151407e-01, -3.7676156e-02, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 8.1197602e-01, -7.8640449e-01,  1.2785778e-02, ...,\n",
       "         8.1012701e-04,  8.1012701e-04,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.security.metrics import shapr_score\n",
    "\n",
    "y_pred_train = proxy.predict(train['X'])\n",
    "y_pred_test = proxy.predict(test['X'])\n",
    "\n",
    "shapr_score(train['y'], test['y'], y_pred_train, y_pred_test, train_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kcosta/.local/share/hatch/env/virtual/holisticai/6RE4VnP4/holisticai/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [16] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/kcosta/.local/share/hatch/env/virtual/holisticai/6RE4VnP4/holisticai/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "/home/kcosta/.local/share/hatch/env/virtual/holisticai/6RE4VnP4/holisticai/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [16] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/kcosta/.local/share/hatch/env/virtual/holisticai/6RE4VnP4/holisticai/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.978960396039604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.security.commons import DataMinimizer\n",
    "from holisticai.security.metrics import data_minimization_score\n",
    "\n",
    "dmin = DataMinimizer(proxy=proxy, selector_types=[\"Percentile\", \"Variance\"])\n",
    "dmin.fit(train['X'], train['y'])\n",
    "\n",
    "y_pred_test = proxy.predict(test['X'])\n",
    "y_pred_test_dm = dmin.predict(test['X'])\n",
    "\n",
    "\n",
    "data_minimization_score(test['y'], y_pred_test, y_pred_test_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Privacy Risk Score for test:  0.4568734634681075 0.15002356864007632\n"
     ]
    }
   ],
   "source": [
    "from holisticai.security.metrics import privacy_risk_score\n",
    "\n",
    "target_shadow = train.train_test_split(test_size=0.4, random_state=42)\n",
    "\n",
    "X_shadow_train = target_shadow['test']['X']\n",
    "y_shadow_train = target_shadow['test']['y']\n",
    "\n",
    "shadow_model = RandomForestClassifier(random_state=42)\n",
    "shadow_model.fit(X_shadow_train, y_shadow_train)\n",
    "\n",
    "shadow_train_probs = shadow_model.predict_proba(X_shadow_train)\n",
    "shadow_test_probs = shadow_model.predict_proba(test['X'])\n",
    "target_test_probs = proxy.predict_proba(test['X'])\n",
    "\n",
    "risk_score_test = privacy_risk_score((shadow_train_probs, y_shadow_train), (shadow_test_probs, test['y']), (target_test_probs, test['y']))\n",
    "print(\"Mean Privacy Risk Score for test: \", risk_score_test.mean(), risk_score_test.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Robustness\n",
    "\n",
    "Robustness metrics are measures used to evaluate how well machine learning models maintain performance under varying conditions, such as data shifts, adversarial inputs, or environmental changes. These metrics help assess a modelâ€™s resilience and reliability in real-world applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Degradation Factor (ADF) is a robustness metric that detects the first point of significant accuracy drop as a dataset is gradually reduced, allowing for the prediction of performance shifts due to changing data distributions. Here is an exampel how to use the metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kcosta/repos/hai/holisticai/src/holisticai/robustness/metrics/dataset_shift/_accuracy_degradation_profile.py:526: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_summary_df = pd.concat([results_summary_df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.robustness.metrics import (\n",
    "    accuracy_degradation_profile,\n",
    "    accuracy_degradation_factor,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "results = accuracy_degradation_profile(test['X'], \n",
    "                                    test['y'], \n",
    "                                    y_test_pred, \n",
    "                                    n_neighbors = 50,\n",
    "                                    step_size = 0.02,\n",
    "                                    )\n",
    "accuracy_degradation_factor(pd.DataFrame(results.data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
