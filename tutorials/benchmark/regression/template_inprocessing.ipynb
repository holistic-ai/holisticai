{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template - Bias Mitigation Benchmark ([Holistic AI](https://research.holisticai.com))\n",
    "\n",
    "**Task:** Regression\n",
    "\n",
    "**Type:** Inprocessing\n",
    "\n",
    "\n",
    "This notebook is a template for the Bias Mitigation Benchmark. It can be used to mitigate bias in datasets and models. The notebook is based on the [Holistic AI open source library](https://github.com/holistic-ai/holisticai) and follows the bias mitigation benchmark outlined in [Holistic AI](https://research.holisticai.com).\n",
    "\n",
    "### Template Structure\n",
    "\n",
    "The template have the following steps:\n",
    "\n",
    "1. Setup definition: \n",
    "    - select a task: `binary_classification`, `multiclass_classification`, `regression`, `clustering`, `recommender`\n",
    "    - select a type: `inprocessing`, `preprocessing`, `postprocessing`\n",
    "2. Mitigator class\n",
    "    - create a class for you custom mitigator\n",
    "3. Evaluation\n",
    "    - evaluate your mitigator and compare it with other mitigators\n",
    "4. Submission\n",
    "    - do you have good results? Then submit your mitigator to the Bias Mitigation Benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_classification', 'multiclass_classification', 'regression', 'clustering', 'recommender']\n"
     ]
    }
   ],
   "source": [
    "from holisticai.benchmark.tasks import task_name, get_task\n",
    "\n",
    "print(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a task\n",
    "task = get_task(\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Average RFS</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitigator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExponentiatedGradientReduction</th>\n",
       "      <td>1.156216</td>\n",
       "      <td>1.156216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearchReduction</th>\n",
       "      <td>1.049938</td>\n",
       "      <td>1.049938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                         Average RFS     crime\n",
       "Mitigator                                            \n",
       "ExponentiatedGradientReduction     1.156216  1.156216\n",
       "GridSearchReduction                1.049938  1.049938"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark for the task by type\n",
    "task.benchmark(type='inprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Mitigator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fairlearn.reductions import DemographicParity, GridSearch\n",
    "\n",
    "class MyInprocessingMitigator:\n",
    "    \"\"\"\n",
    "    My Inprocessing Mitigator\n",
    "\n",
    "    The input data is expected to be a numpy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, X, y_true, group_a, group_b, estimator_, **kargs):\n",
    "\n",
    "        sensitive_features = np.stack([group_a, group_b], axis=1)\n",
    "\n",
    "        self.model_ = GridSearch(\n",
    "            estimator=estimator_,\n",
    "            constraints=DemographicParity(),\n",
    "            constraint_weight=0.5,\n",
    "        )\n",
    "\n",
    "        self.model_.fit(X, y_true, sensitive_features=sensitive_features)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model_.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Benchmark initialized for MyInprocessingMitigator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:46<00:00, 46.87s/it]\n"
     ]
    }
   ],
   "source": [
    "my_mitigator = MyInprocessingMitigator()\n",
    "\n",
    "task.run_benchmark(custom_mitigator = my_mitigator, type = 'inprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_62ee5_row1_col0, #T_62ee5_row1_col1 {\n",
       "  background: mediumslateblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_62ee5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Dataset</th>\n",
       "      <th id=\"T_62ee5_level0_col0\" class=\"col_heading level0 col0\" >Average RFS</th>\n",
       "      <th id=\"T_62ee5_level0_col1\" class=\"col_heading level0 col1\" >crime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Mitigator</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_62ee5_level0_row0\" class=\"row_heading level0 row0\" >ExponentiatedGradientReduction</th>\n",
       "      <td id=\"T_62ee5_row0_col0\" class=\"data row0 col0\" >1.156216</td>\n",
       "      <td id=\"T_62ee5_row0_col1\" class=\"data row0 col1\" >1.156216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ee5_level0_row1\" class=\"row_heading level0 row1\" >MyInprocessingMitigator</th>\n",
       "      <td id=\"T_62ee5_row1_col0\" class=\"data row1 col0\" >1.060779</td>\n",
       "      <td id=\"T_62ee5_row1_col1\" class=\"data row1 col1\" >1.060779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_62ee5_level0_row2\" class=\"row_heading level0 row2\" >GridSearchReduction</th>\n",
       "      <td id=\"T_62ee5_row2_col0\" class=\"data row2 col0\" >1.049938</td>\n",
       "      <td id=\"T_62ee5_row2_col1\" class=\"data row2 col1\" >1.049938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd4a2a3b1f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the link in your browser: https://forms.office.com/r/Vd6FT4eNL2\n"
     ]
    }
   ],
   "source": [
    "task.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
