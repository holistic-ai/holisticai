{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template - Bias Mitigation Benchmark ([Holistic AI](https://research.holisticai.com))\n",
    "\n",
    "**Task:** Clustering\n",
    "\n",
    "**Type:** Preprocessing\n",
    "\n",
    "\n",
    "This notebook is a template for the Bias Mitigation Benchmark. It can be used to mitigate bias in datasets and models. The notebook is based on the [Holistic AI open source library](https://github.com/holistic-ai/holisticai) and follows the bias mitigation benchmark outlined in [Holistic AI](https://research.holisticai.com).\n",
    "\n",
    "### Template Structure\n",
    "\n",
    "The template have the following steps:\n",
    "\n",
    "1. Setup definition: \n",
    "    - select a task: `binary_classification`, `multiclass_classification`, `regression`, `clustering`, `recommender`\n",
    "    - select a type: `inprocessing`, `preprocessing`, `postprocessing`\n",
    "2. Mitigator class\n",
    "    - create a class for you custom mitigator\n",
    "3. Evaluation\n",
    "    - evaluate your mitigator and compare it with other mitigators\n",
    "4. Submission\n",
    "    - do you have good results? Then submit your mitigator to the Bias Mitigation Benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_classification', 'multiclass_classification', 'regression', 'clustering', 'recommender']\n"
     ]
    }
   ],
   "source": [
    "from holisticai.benchmark.tasks import task_name, get_task\n",
    "\n",
    "print(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a task\n",
    "task = get_task(\"clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Average Cluster Balance</th>\n",
       "      <th>heart</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitigator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FairletClusteringPreprocessing</th>\n",
       "      <td>0.948859</td>\n",
       "      <td>0.948859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                         Average Cluster Balance     heart\n",
       "Mitigator                                                        \n",
       "FairletClusteringPreprocessing                 0.948859  0.948859"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark for the task by type\n",
    "task.benchmark(type='preprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Mitigator Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "\n",
    "from holisticai.bias.mitigation.commons.fairlet_clustering.decompositions import (\n",
    "    DecompositionMixin,\n",
    "    ScalableFairletDecomposition,\n",
    "    VanillaFairletDecomposition,\n",
    ")\n",
    "from holisticai.utils.models.cluster import KCenters, KMedoids\n",
    "from holisticai.utils.transformers.bias import BMPreprocessing as BMPre\n",
    "\n",
    "DECOMPOSITION_CATALOG = {\n",
    "    \"Scalable\": ScalableFairletDecomposition,\n",
    "    \"Vanilla\": VanillaFairletDecomposition,\n",
    "}\n",
    "CLUSTERING_CATALOG = {\"KCenter\": KCenters, \"KMedoids\": KMedoids}\n",
    "\n",
    "\n",
    "class MyPreprocessingMitigator(BaseEstimator, BMPre):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        decomposition: Union[\"str\", \"DecompositionMixin\"] = \"Vanilla\",\n",
    "        p: Optional[str] = 1,\n",
    "        q: Optional[float] = 3,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "            decomposition : str\n",
    "                Fairlet decomposition strategy, available: Vanilla, Scalable, MCF\n",
    "\n",
    "            p : int\n",
    "                fairlet decomposition parameter for Vanilla and Scalable strategy\n",
    "\n",
    "            q : int\n",
    "                fairlet decomposition parameter for Vanilla and Scalable strategy\n",
    "\n",
    "            seed : int\n",
    "                Random seed.\n",
    "        \"\"\"\n",
    "        self.decomposition = DECOMPOSITION_CATALOG[decomposition](p=p, q=q)\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit_transform(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        group_a: np.ndarray,\n",
    "        group_b: np.ndarray,\n",
    "        sample_weight: Optional[np.ndarray] = None,\n",
    "    ):\n",
    "        params = self._load_data(\n",
    "            X=X, sample_weight=sample_weight, group_a=group_a, group_b=group_b\n",
    "        )\n",
    "        X = params[\"X\"]\n",
    "        sample_weight = params[\"sample_weight\"]\n",
    "        group_a = params[\"group_a\"].astype(\"int32\")\n",
    "        group_b = params[\"group_b\"].astype(\"int32\")\n",
    "        np.random.seed(self.seed)\n",
    "        fairlets, fairlet_centers, fairlet_costs = self.decomposition.fit_transform(\n",
    "            X, group_a, group_b\n",
    "        )\n",
    "        Xt = np.zeros_like(X)\n",
    "        mapping = np.zeros(len(X), dtype=\"int32\")\n",
    "        centers = np.array([X[fairlet_center] for fairlet_center in fairlet_centers])\n",
    "        for i, fairlet in enumerate(fairlets):\n",
    "            Xt[fairlet] = X[fairlet_centers[i]]\n",
    "            mapping[fairlet] = i\n",
    "            sample_weight[fairlet] = len(fairlet) / len(X)\n",
    "\n",
    "        self.update_estimator_param(\"sample_weight\", sample_weight)\n",
    "        self.sample_weight = sample_weight\n",
    "        self.X = X\n",
    "        self.mapping = mapping\n",
    "        self.centers = centers\n",
    "        return Xt\n",
    "\n",
    "    def transform(self, X):\n",
    "        fairlets_midxs = pairwise_distances_argmin(X, Y=self.X)\n",
    "        return self.centers[self.mapping[fairlets_midxs]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Benchmark initialized for MyPreprocessingMitigator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "my_mitigator = MyPreprocessingMitigator()\n",
    "\n",
    "task.run_benchmark(mitigator = my_mitigator, type = 'preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_58161_row0_col0, #T_58161_row0_col1 {\n",
       "  background: mediumslateblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_58161\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Dataset</th>\n",
       "      <th id=\"T_58161_level0_col0\" class=\"col_heading level0 col0\" >Average Cluster Balance</th>\n",
       "      <th id=\"T_58161_level0_col1\" class=\"col_heading level0 col1\" >heart</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Mitigator</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_58161_level0_row0\" class=\"row_heading level0 row0\" >MyPreprocessingMitigator</th>\n",
       "      <td id=\"T_58161_row0_col0\" class=\"data row0 col0\" >0.953980</td>\n",
       "      <td id=\"T_58161_row0_col1\" class=\"data row0 col1\" >0.953980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_58161_level0_row1\" class=\"row_heading level0 row1\" >FairletClusteringPreprocessing</th>\n",
       "      <td id=\"T_58161_row1_col0\" class=\"data row1 col0\" >0.948859</td>\n",
       "      <td id=\"T_58161_row1_col1\" class=\"data row1 col1\" >0.948859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa81c963070>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the link in your browser:\n"
     ]
    }
   ],
   "source": [
    "task.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
