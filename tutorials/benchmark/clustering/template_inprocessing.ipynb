{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template - Bias Mitigation Benchmark ([Holistic AI](https://research.holisticai.com))\n",
    "\n",
    "**Task:** Clustering\n",
    "\n",
    "**Type:** Inprocessing\n",
    "\n",
    "\n",
    "This notebook is a template for the Bias Mitigation Benchmark. It can be used to mitigate bias in datasets and models. The notebook is based on the [Holistic AI open source library](https://github.com/holistic-ai/holisticai) and follows the bias mitigation benchmark outlined in [Holistic AI](https://research.holisticai.com).\n",
    "\n",
    "### Template Structure\n",
    "\n",
    "The template have the following steps:\n",
    "\n",
    "1. Setup definition: \n",
    "    - select a task: `binary_classification`, `multiclass_classification`, `regression`, `clustering`, `recommender`\n",
    "    - select a type: `inprocessing`, `preprocessing`, `postprocessing`\n",
    "2. Mitigator class\n",
    "    - create a class for you custom mitigator\n",
    "3. Evaluation\n",
    "    - evaluate your mitigator and compare it with other mitigators\n",
    "4. Submission\n",
    "    - do you have good results? Then submit your mitigator to the Bias Mitigation Benchmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary_classification', 'multiclass_classification', 'regression', 'clustering', 'recommender']\n"
     ]
    }
   ],
   "source": [
    "from holisticai.benchmark.tasks import task_name, get_task\n",
    "\n",
    "print(task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a task\n",
    "task = get_task(\"clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Average RFS</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitigator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExponentiatedGradientReduction</th>\n",
       "      <td>1.156216</td>\n",
       "      <td>1.156216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearchReduction</th>\n",
       "      <td>1.049938</td>\n",
       "      <td>1.049938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset                         Average RFS     crime\n",
       "Mitigator                                            \n",
       "ExponentiatedGradientReduction     1.156216  1.156216\n",
       "GridSearchReduction                1.049938  1.049938"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# benchmark for the task by type\n",
    "task.benchmark(type='inprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Mitigator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics.pairwise import pairwise_distances, pairwise_distances_argmin\n",
    "\n",
    "from holisticai.utils.transformers.bias import BMInprocessing as BMImp\n",
    "from holisticai.utils.transformers.bias import SensitiveGroups\n",
    "\n",
    "from holisticai.bias.mitigation.inprocessing.fair_k_center_clustering.algorithms import (\n",
    "    fair_k_center_APPROX,\n",
    "    heuristic_greedy_on_each_group,\n",
    "    heuristic_greedy_till_constraint_is_satisfied,\n",
    ")\n",
    "\n",
    "STRATEGIES_CATALOG = {\n",
    "    \"Fair K-Center\": fair_k_center_APPROX,\n",
    "    \"Heuristic Greedy by Group\": heuristic_greedy_on_each_group,\n",
    "    \"Heuristic Greedy by Constraint\": heuristic_greedy_till_constraint_is_satisfied,\n",
    "}\n",
    "\n",
    "\n",
    "class MyInprocessingMitigator(BaseEstimator, BMImp):\n",
    "    \"\"\"\n",
    "    Fair K-Center Clustering inprocessing bias mitigation implements an approximation algorithm\n",
    "    for the k-centers problem under the fairness contraint with running time linear in the\n",
    "    size of the dataset and k (number of cluster).\n",
    "\n",
    "    Reference\n",
    "    ---------\n",
    "        Kleindessner, Matth√§us, Pranjal Awasthi, and Jamie Morgenstern. \"Fair k-center clustering\n",
    "        for data summarization.\" International Conference on Machine Learning. PMLR, 2019.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        req_nr_per_group: Optional[list] = [200, 200],\n",
    "        nr_initially_given: Optional[int] = 100,\n",
    "        strategy: Optional[str] = \"Fair K-Center\",\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        req_nr_per_group : list\n",
    "            Number of cluster for each group that will be founded.\n",
    "            - Integer-vector of length m with entries in 0,...,k.\n",
    "            - Sum of all entries must be equal to k (total number of clusters).\n",
    "\n",
    "        nr_initially_given: int\n",
    "            Number of initial random centers.\n",
    "\n",
    "        strategy: Strategy used to compute the cluster centers. Available are:\n",
    "            - 'Fair K-Center' (default)\n",
    "            - 'Heuristic Greedy by Group'\n",
    "            - 'Heuristic Greedy by Constraint'\n",
    "\n",
    "        seed: int,\n",
    "            Initial random seed.\n",
    "        \"\"\"\n",
    "        self.req_nr_per_group = np.array(req_nr_per_group)\n",
    "        self.nr_initially_given = nr_initially_given\n",
    "        self.strategy = strategy\n",
    "        self.seed = seed\n",
    "        self.sensgroup = SensitiveGroups()\n",
    "\n",
    "    def fit(self, X, group_a, group_b):\n",
    "        \"\"\"\n",
    "        Fit model using Fair K-Center Clustering.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : matrix-like\n",
    "            Input matrix\n",
    "        group_a : array-like\n",
    "            Group membership vector (binary)\n",
    "        group_b : array-like\n",
    "            Group membership vector (binary)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Self\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        params = self._load_data(X=X, group_a=group_a, group_b=group_b)\n",
    "        X = params[\"X\"]\n",
    "        group_a = params[\"group_a\"]\n",
    "        group_b = params[\"group_b\"]\n",
    "\n",
    "        sensitive_groups = np.c_[group_a, group_b]\n",
    "        p_attr = np.array(\n",
    "            self.sensgroup.fit_transform(sensitive_groups, convert_numeric=True)\n",
    "        )\n",
    "\n",
    "        n = len(X)\n",
    "        dmat = pairwise_distances(X, metric=\"l1\")\n",
    "        initially_given = np.random.choice(\n",
    "            n, size=self.nr_initially_given, replace=False\n",
    "        )\n",
    "        centers = STRATEGIES_CATALOG[self.strategy](\n",
    "            dmat, p_attr, self.req_nr_per_group, initially_given\n",
    "        )\n",
    "        cost = np.amax(\n",
    "            np.amin(\n",
    "                dmat[np.ix_(np.hstack((centers, initially_given)), np.arange(n))],\n",
    "                axis=0,\n",
    "            )\n",
    "        )\n",
    "        self.centers = centers\n",
    "        self.initially_given = initially_given\n",
    "        self.cost = cost\n",
    "\n",
    "        self.centroids = X[self.centers]\n",
    "        self.cluster_centers_ = X[self.all_centers]\n",
    "\n",
    "        self.labels_ = self.all_centers[\n",
    "            pairwise_distances_argmin(X, Y=self.cluster_centers_, metric=\"l1\")\n",
    "        ]\n",
    "        self.center_groups_ = p_attr[self.all_centers]\n",
    "\n",
    "    @property\n",
    "    def all_centers(self):\n",
    "        return np.concatenate([self.centers, self.initially_given], axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return pairwise_distances(self.cluster_centers_, X, metric=\"l1\").argmin(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Benchmark initialized for MyInprocessingMitigator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:37<00:00, 37.70s/it]\n"
     ]
    }
   ],
   "source": [
    "my_mitigator = MyInprocessingMitigator()\n",
    "\n",
    "task.run_benchmark(mitigator = my_mitigator, type = 'inprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_42fc0_row2_col0, #T_42fc0_row2_col1 {\n",
       "  background: mediumslateblue;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_42fc0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Dataset</th>\n",
       "      <th id=\"T_42fc0_level0_col0\" class=\"col_heading level0 col0\" >Average RFS</th>\n",
       "      <th id=\"T_42fc0_level0_col1\" class=\"col_heading level0 col1\" >crime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Mitigator</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_42fc0_level0_row0\" class=\"row_heading level0 row0\" >ExponentiatedGradientReduction</th>\n",
       "      <td id=\"T_42fc0_row0_col0\" class=\"data row0 col0\" >1.156216</td>\n",
       "      <td id=\"T_42fc0_row0_col1\" class=\"data row0 col1\" >1.156216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fc0_level0_row1\" class=\"row_heading level0 row1\" >GridSearchReduction</th>\n",
       "      <td id=\"T_42fc0_row1_col0\" class=\"data row1 col0\" >1.049938</td>\n",
       "      <td id=\"T_42fc0_row1_col1\" class=\"data row1 col1\" >1.049938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_42fc0_level0_row2\" class=\"row_heading level0 row2\" >MyInprocessingMitigator</th>\n",
       "      <td id=\"T_42fc0_row2_col0\" class=\"data row2 col0\" >0.893453</td>\n",
       "      <td id=\"T_42fc0_row2_col1\" class=\"data row2 col1\" >0.893453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fed1cb8e4d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluate_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening the link in your browser:\n"
     ]
    }
   ],
   "source": [
    "task.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
