Bias
====

Machine learning can be used in critical applications, like recruitment or the judicial system. In these cases, it is especially important to ensure that algorithms do not discriminate and treat everyone equally. Sometimes, however, it is possible that a model presents hidden prejudice in its decision-making process. If this results in disadvantages to an individual or a group of individuals, we say that the algorithm presents bias.

We define bias as an unwanted prejudice in the decisions made by an AI system that are systematically disadvantageous to a person or group. Multiple types of bias exist, and can be unknowingly introduced in algorithms at any stage of the development process, whether during data generation or model building.

.. contents:: Table of Contents
   :local:
   :depth: 1

Measuring and Mitigation
------------------------

To avoid bias, it is important to measure and mitigate it. This section provides an overview of techniques to measure and mitigate bias in machine learning models. Below are the metrics and mitigation techniques that can be used to address bias in AI systems: 

.. toctree::
    :maxdepth: 2

    metrics
    mitigation