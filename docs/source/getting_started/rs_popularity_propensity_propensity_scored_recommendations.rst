**Propensity-Scored Recommendations**
======================================

**Introduction**
----------------
Propensity-scored recommendations are a method designed to handle selection biases in the evaluation and training of recommender systems. This approach leverages techniques from causal inference to provide unbiased performance estimators and improve prediction accuracy, even when the data is Missing Not At Random (MNAR).

**Description**
---------------
The propensity-scored recommendations method addresses the problem of biased data in recommender systems, where users typically rate items they like, leading to a non-random missing data pattern. The method involves estimating the probability (propensity) that a user will rate an item and using these propensities to adjust the training and evaluation processes.

The main characteristics of the method include:

- Estimating propensities for each user-item pair.
- Using these propensities to weight the observed data.
- Applying the Inverse-Propensity-Scoring (IPS) estimator to obtain unbiased performance measures.
- Integrating propensity scores into an Empirical Risk Minimization (ERM) framework for learning.

**Equations/Algorithms**
------------------------

The IPS estimator is defined as:

.. math::
    :label: ips-estimator

    \hat{R}_{IPS}(\hat{Y} | P) = \frac{1}{U \cdot I} \sum_{(u,i): O_{u,i} = 1} \frac{\delta_{u,i}(Y, \hat{Y})}{P_{u,i}}

where:

- :math:`\hat{R}_{IPS}(\hat{Y} | P)` is the IPS estimator.
- :math:`U` and :math:`I` are the number of users and items, respectively.
- :math:`O_{u,i}` is the observation indicator for user :math:`u` and item :math:`i`.
- :math:`\delta_{u,i}(Y, \hat{Y})` is the loss function.
- :math:`P_{u,i}` is the propensity score for user :math:`u` and item :math:`i`.

The training objective for matrix factorization with propensity scoring is:

.. math::
    :label: mf-objective

    \arg\min_{V, W, A} \left\{ \sum_{O_{u,i} = 1} \frac{\delta_{u,i}(Y, V^T W + A)}{P_{u,i}} + \lambda \left( \|V\|_F^2 + \|W\|_F^2 \right) \right\}

where:

- :math:`V` and :math:`W` are the user and item latent factor matrices.
- :math:`A` encodes the offset terms.
- :math:`\lambda` is the regularization parameter.

**Usage Examples**
------------------
The method was tested on two real-world datasets:

1. **Yahoo! R3 Dataset**: This dataset contains user-song ratings. The training set includes over 300K ratings for songs self-selected by 15,400 users. The test set contains ratings from a subset of 5,400 users who rated 10 randomly chosen songs. Propensities were estimated using Naive Bayes.

2. **Coat Shopping Dataset**: This dataset simulates MNAR data of customers shopping for coats online. The training data was generated by asking users to rate 24 self-selected coats and 16 randomly picked ones. Propensities were estimated using logistic regression based on user and item covariates.

**Advantages and Limitations**
------------------------------

*Advantages:*

- Provides unbiased performance estimators despite biased data.
- Improves prediction accuracy in real-world datasets.
- Conceptually simple and scalable.
- Does not require generative assumptions about the rating model.

*Limitations:*

- Requires accurate estimation of propensities, which can be challenging.
- Performance depends on the quality of the propensity estimation.
- May require additional computational resources for propensity estimation and weighted training.

**References**
---------------
1. Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as treatments: Debiasing learning and evaluation. arXiv preprint arXiv:1602.05352 (2016).