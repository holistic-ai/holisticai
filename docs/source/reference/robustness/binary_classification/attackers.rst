Attackers
=========

`holisticai.robustness.attackers` is a Python module designed to evaluate the robustness of machine learning models. The module includes various strategies to test and enhance the resilience of these models, such as:

Binary Classification
=====================

The following attackers are available for binary classification models:

.. autosummary::
    :toctree: .generated/

    holisticai.robustness.attackers.HopSkipJump
    holisticai.robustness.attackers.ZooAttack