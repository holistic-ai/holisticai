<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Measuring Bias in classification &mdash; holisticai  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom_style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Measuring Bias in regression" href="measuring_bias_regression.html" />
    <link rel="prev" title="Measuring bias" href="../../measuring_bias.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            holisticai
              <img src="../../_static/holistic_ai.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mitigation.html">Mitigation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plotting.html">Plotting</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../measuring_bias.html">Measuring bias</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#"><strong>Measuring Bias in classification</strong></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Load-the-data"><strong>Load the data</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="#Data-Exploration"><strong>Data Exploration</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="#Train-a-model"><strong>Train a model</strong></a></li>
<li class="toctree-l3"><a class="reference internal" href="#Measure-bias"><strong>Measure bias</strong></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_regression.html"><strong>Measuring Bias in regression</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_recommender.html"><strong>Measuring Bias in recommender systems</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_clustering.html"><strong>Measuring Bias in clustering</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="measuring_bias_multiclass.html"><strong>Measuring Bias in multiclass classification</strong></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../mitigating_bias.html">Mitigating bias</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">holisticai</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../measuring_bias.html">Measuring bias</a></li>
      <li class="breadcrumb-item active"><strong>Measuring Bias in classification</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/measuring_bias_tutorials/measuring_bias_classification.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Measuring-Bias-in-classification">
<h1><strong>Measuring Bias in classification</strong><a class="headerlink" href="#Measuring-Bias-in-classification" title="Permalink to this heading"></a></h1>
<p>This notebook is a tutorial on auditing bias within a binary classification task. We will use the holisticai library both in the <strong>data exploration</strong> and <strong>measure bias</strong> sections, introducing some of the functions we have created to help study algorithmic bias.</p>
<p>The sections are organised as follows : 1. Load the data : we load the law school dataset as a pandas DataFrame 2. Data Exploration : some preliminary analysis of the data 3. Train a Model : we train a simple logistic regression model (sklearn) 4. Measure Bias : we compute a few bias metrics, and comment on their meaning</p>
<section id="Load-the-data">
<h2><strong>Load the data</strong><a class="headerlink" href="#Load-the-data" title="Permalink to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Imports
import numpy as np
import pandas as pd
import sys
sys.path.append(&#39;../../&#39;)
</pre></div>
</div>
</div>
<p>We host a few example datasets on the holisticai library for quick loading and experimentation. Here we load and use the Law School dataset. The goal of this dataset is the prediction of the binary attribute ‘bar’ (whether a student passes the law school bar). The protected attributes are race and gender. We pay special attention to race in this case, because preliminary exploration hints there is strong inequality on that sensitive attribute.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Get data
from holisticai.datasets import load_law_school
df = load_law_school()[&#39;frame&#39;]
df
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>decile1</th>
      <th>decile3</th>
      <th>fam_inc</th>
      <th>lsat</th>
      <th>ugpa</th>
      <th>gender</th>
      <th>race1</th>
      <th>cluster</th>
      <th>fulltime</th>
      <th>bar</th>
      <th>ugpagt3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>62.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.0</td>
      <td>44.0</td>
      <td>3.5</td>
      <td>female</td>
      <td>white</td>
      <td>1</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>62.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>29.0</td>
      <td>3.5</td>
      <td>female</td>
      <td>white</td>
      <td>2</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>61.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>3.0</td>
      <td>37.0</td>
      <td>3.4</td>
      <td>male</td>
      <td>white</td>
      <td>1</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>60.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>43.0</td>
      <td>3.3</td>
      <td>female</td>
      <td>white</td>
      <td>1</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>57.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>41.0</td>
      <td>3.3</td>
      <td>female</td>
      <td>white</td>
      <td>4</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>20795</th>
      <td>60.0</td>
      <td>9.0</td>
      <td>8.0</td>
      <td>4.0</td>
      <td>42.0</td>
      <td>3.0</td>
      <td>male</td>
      <td>white</td>
      <td>5</td>
      <td>1</td>
      <td>TRUE</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>20796</th>
      <td>61.0</td>
      <td>4.0</td>
      <td>9.0</td>
      <td>4.0</td>
      <td>29.5</td>
      <td>3.5</td>
      <td>male</td>
      <td>white</td>
      <td>3</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>20797</th>
      <td>62.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>33.0</td>
      <td>3.1</td>
      <td>male</td>
      <td>non-white</td>
      <td>3</td>
      <td>1</td>
      <td>FALSE</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>20798</th>
      <td>65.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>32.0</td>
      <td>3.0</td>
      <td>male</td>
      <td>white</td>
      <td>3</td>
      <td>2</td>
      <td>TRUE</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>20799</th>
      <td>60.0</td>
      <td>9.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>36.0</td>
      <td>3.2</td>
      <td>male</td>
      <td>non-white</td>
      <td>4</td>
      <td>1</td>
      <td>TRUE</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>20800 rows × 12 columns</p>
</div></div>
</div>
</section>
<section id="Data-Exploration">
<h2><strong>Data Exploration</strong><a class="headerlink" href="#Data-Exploration" title="Permalink to this heading"></a></h2>
<p>We import some of the holisticai plotters for quick exploration of the data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from holisticai.bias.plots import group_pie_plot, success_rate_plot
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># replace the 0,1 with text data for readability

p_attr = df[&#39;race1&#39;] # protected attribute (race)
y = df[&#39;bar&#39;]        # binary label vector
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>group_pie_plot(p_attr)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;AxesSubplot:&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_10_1.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_10_1.png" />
</div>
</div>
<p>The proportion of white people in law school is very high, allready we observe there is a big representation issue.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>success_rate_plot(p_attr, y)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/measuring_bias_tutorials/../../holisticai/bias/plots/_bias_multiclass_plots.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  sr_list = sr_list.append(sr_tot)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;AxesSubplot:xlabel=&#39;Group&#39;, ylabel=&#39;Frequency&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_12_2.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_12_2.png" />
</div>
</div>
<p>We also observe that the white group has a much higher pass rate (within the dataset) than the non-white group.</p>
</section>
<section id="Train-a-model">
<h2><strong>Train a model</strong><a class="headerlink" href="#Train-a-model" title="Permalink to this heading"></a></h2>
<p>encode our dataframe categorical columns</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># simple preprocessing before training.
df_enc = df.copy()
df_enc[&#39;bar&#39;] = df_enc[&#39;bar&#39;].replace({&#39;FALSE&#39;:0, &#39;TRUE&#39;:1})
</pre></div>
</div>
</div>
<p>Here we train a Logistic Regression classifier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.model_selection import train_test_split

# split features and target, then train test split
X = df_enc.drop(columns=[&#39;bar&#39;, &#39;ugpagt3&#39;])
y = df_enc[&#39;bar&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

# train a model, do not forget to standard scale data
scaler = StandardScaler()
X_train_t = scaler.fit_transform(X_train.drop(columns=[&#39;race1&#39;, &#39;gender&#39;]))
LR = LogisticRegression(random_state=42, max_iter=500)
LR.fit(X_train_t, y_train)
X_test_t = scaler.transform(X_test.drop(columns=[&#39;race1&#39;, &#39;gender&#39;]))
y_pred = LR.predict(X_test_t)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy metrics from sklearn
from sklearn import metrics

# dictionnary of metrics
metrics_dict={
        &quot;Accuracy&quot;: metrics.accuracy_score,
        &quot;Balanced accuracy&quot;: metrics.balanced_accuracy_score,
        &quot;Precision&quot;: metrics.precision_score,
        &quot;Recall&quot;: metrics.recall_score,
        &quot;F1-Score&quot;: metrics.f1_score}

# efficacy metrics dataframe helper tool
def metrics_dataframe(y_pred, y_true, metrics_dict=metrics_dict):
    metric_list = [[pf, fn(y_true, y_pred)] for pf, fn in metrics_dict.items()]
    return pd.DataFrame(metric_list, columns=[&quot;Metric&quot;, &quot;Value&quot;]).set_index(&quot;Metric&quot;)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># compute efficacy metrics
metrics_dataframe(y_pred, y_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.902724</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.605856</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.913333</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.984372</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.947523</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
<section id="Measure-bias">
<h2><strong>Measure bias</strong><a class="headerlink" href="#Measure-bias" title="Permalink to this heading"></a></h2>
<p>The holisticai.bias.metrics module contains a range of metrics useful in evaluating the fairness of algorithmic decisions. In this case we use only a few of the metrics relevant to a classification task.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import some bias metrics
from holisticai.bias.metrics import statistical_parity
from holisticai.bias.metrics import disparate_impact
from holisticai.bias.metrics import accuracy_diff
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># set up groups, prediction array and true (aka target/label) array.
group_a = X_test[&quot;race1&quot;]==&#39;non-white&#39;  # non-white vector
group_b = X_test[&quot;race1&quot;]==&#39;white&#39;      # white vector
y_pred  = LR.predict(X_test_t)          # prediction vector
y_true  = y_test                        # true vector
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from holisticai.bias.plots import success_rate_plot
p_attr = X_test[&quot;race1&quot;]
success_rate_plot(p_attr, y_pred)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/giuliofilippi/Documents/GitHub2/holisticai/tutorials/measuring_bias_tutorials/../../holisticai/bias/plots/_bias_multiclass_plots.py:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  sr_list = sr_list.append(sr_tot)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;AxesSubplot:xlabel=&#39;Group&#39;, ylabel=&#39;Frequency&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_26_2.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_26_2.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># compute statistical parity
statistical_parity(group_a, group_b, y_pred)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-0.1583838383838384
</pre></div></div>
</div>
<p>The statistical parity indicates the difference in success rate between non-white and white groups. In this case it is outside of ranges considered fair (-0.1, 0.1).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># compute disparate impact
disparate_impact(group_a, group_b, y_pred)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.8394758394758395
</pre></div></div>
</div>
<p>The disparate impact on the other hand is within the fair range (0.8, 1.2). This shows the importance of considering many different metrics to get a holistic picture of the situation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># compute accuracy difference
accuracy_diff(group_a, group_b, y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
-0.12809812409812404
</pre></div></div>
</div>
<p>The above metric is different from the first two in that it also uses the target values, this is an equality of opportunity metric. A value of -0.12 shows that the classifier we trained is less accurate on non-white group than white group. This is expected because of the data imbalance.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from holisticai.bias.plots import accuracy_bar_plot
# set up protected attribute
p_attr = X_test[&quot;race1&quot;]
accuracy_bar_plot(p_attr, y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;AxesSubplot:xlabel=&#39;Group&#39;, ylabel=&#39;Accuracy&#39;&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_33_1.png" src="../../_images/tutorials_measuring_bias_tutorials_measuring_bias_classification_33_1.png" />
</div>
</div>
<p>The above shows the same result as accuracy_diff metric in plot form.</p>
<p><strong>Equality of outcome metrics (batch computation)</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import function for batch computation
from holisticai.bias.metrics import classification_bias_metrics
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;equal_outcome&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.158384</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.839476</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.839476</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.863802</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p><strong>Equality of opportunity metrics (batch computation)</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;equal_opportunity&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>-0.069042</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.344579</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>-0.206811</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>-0.128098</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>For instance the false positive rate difference of 0.34 hints that white people are more likely to be missclassified as passing the bar than non-whites.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../measuring_bias.html" class="btn btn-neutral float-left" title="Measuring bias" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="measuring_bias_regression.html" class="btn btn-neutral float-right" title="Measuring Bias in regression" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Holistic AI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
