<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mitigating Bias in Binary Classification Setting &mdash; holisticai  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/nbsphinx-code-cells.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom_style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Mitigating Bias in Binary Classification with holisticai Pipeline" href="mitigating_bias_classification_pipeline.html" />
    <link rel="prev" title="Mitigating bias" href="../../mitigating_bias.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            holisticai
              <img src="../../_static/holistic_ai.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mitigation.html">Mitigation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../plotting.html">Plotting</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">Utils</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../measuring_bias.html">Measuring bias</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../mitigating_bias.html">Mitigating bias</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#"><strong>Mitigating Bias in Binary Classification Setting</strong></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Load-and-preprocess-Data">Load and preprocess Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Baseline">Baseline</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Preprocessing-Strategies">Preprocessing Strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Reweighing">Reweighing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Learning-Fair-Representations">Learning Fair Representations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Inprocessing-Strategies">Inprocessing Strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Grid-Search-Reduction">Grid Search Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Exponentiated-Gradient-Reduction">Exponentiated Gradient Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Postprocessing-Strategies">Postprocessing Strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Calibrated-Equalized-Odds-mitigation-technique">Calibrated Equalized Odds mitigation technique</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Equalized-Odds-mitigation-technique">Equalized Odds mitigation technique</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Reject-Option-Classification">Reject Option Classification</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mitigating_bias_classification_pipeline.html"><strong>Mitigating Bias in Binary Classification with holisticai Pipeline</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="mitigation_bias_regression_pipeline.html"><strong>Mitigating Bias in regression setting with holisticai Pipeline</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="mitigation_bias_clustering.html"><strong>Mitigating Bias in clustering</strong></a></li>
<li class="toctree-l2"><a class="reference internal" href="mitigation_bias_multiclass.html"><strong>Mitigating Bias in multiclass classification</strong></a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">holisticai</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../mitigating_bias.html">Mitigating bias</a></li>
      <li class="breadcrumb-item active"><strong>Mitigating Bias in Binary Classification Setting</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/mitigating_bias_tutorials/mitigating_bias_classification.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Mitigating-Bias-in-Binary-Classification-Setting">
<h1><strong>Mitigating Bias in Binary Classification Setting</strong><a class="headerlink" href="#Mitigating-Bias-in-Binary-Classification-Setting" title="Permalink to this heading"></a></h1>
<p>This tutorial shows how we can use the holisticai library to implement bias mitigation strategies.</p>
<p>Algorithms Covered:</p>
<ul class="simple">
<li><p>Reweighing [Preprocessing]</p></li>
<li><p>Learning Fair Representations [Preprocessing]</p></li>
<li><p>Grid Search Reduction [Inprocessing]</p></li>
<li><p>Exponentiated Gradient Reduction [Inprocessing]</p></li>
<li><p>Calibrated Equalized Odds [Postprocessing]</p></li>
<li><p>Equalized Odds [Postprocessing]</p></li>
<li><p>Reject Option Classification [Postprocessing]</p></li>
</ul>
<section id="Load-and-preprocess-Data">
<h2>Load and preprocess Data<a class="headerlink" href="#Load-and-preprocess-Data" title="Permalink to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># sys path
import sys
sys.path.append(&#39;../../&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Base Imports
import numpy as np
import pandas as pd

# Settings
np.random.seed(0)
import warnings
warnings.filterwarnings(&quot;ignore&quot;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Adult dataset
from holisticai.datasets import load_adult
from sklearn.model_selection import train_test_split
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Dataset
data = load_adult()

# Dataframe
df = pd.concat([data[&quot;data&quot;], data[&quot;target&quot;]], axis=1)
protected_variables = [&quot;sex&quot;, &quot;race&quot;]
output_variable = [&quot;class&quot;]

# Simple preprocessing
y = df[output_variable].replace({&quot;&gt;50K&quot;: 1, &quot;&lt;=50K&quot;: 0})
X = pd.get_dummies(df.drop(protected_variables + output_variable, axis=1))
group = [&quot;sex&quot;]
group_a = df[group] == &quot;Female&quot;
group_b = df[group] == &quot;Male&quot;
data_ = [X, y, group_a, group_b]

# Train test split
dataset = train_test_split(*data_, test_size=0.2, shuffle=True)
train_data = dataset[::2]
test_data = dataset[1::2]
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># the dataframe
data[&#39;frame&#39;]
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>education-num</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital-gain</th>
      <th>capital-loss</th>
      <th>hours-per-week</th>
      <th>native-country</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>25.0</td>
      <td>Private</td>
      <td>226802.0</td>
      <td>11th</td>
      <td>7.0</td>
      <td>Never-married</td>
      <td>Machine-op-inspct</td>
      <td>Own-child</td>
      <td>Black</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>38.0</td>
      <td>Private</td>
      <td>89814.0</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Farming-fishing</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>50.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>28.0</td>
      <td>Local-gov</td>
      <td>336951.0</td>
      <td>Assoc-acdm</td>
      <td>12.0</td>
      <td>Married-civ-spouse</td>
      <td>Protective-serv</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>3</th>
      <td>44.0</td>
      <td>Private</td>
      <td>160323.0</td>
      <td>Some-college</td>
      <td>10.0</td>
      <td>Married-civ-spouse</td>
      <td>Machine-op-inspct</td>
      <td>Husband</td>
      <td>Black</td>
      <td>Male</td>
      <td>7688.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>4</th>
      <td>18.0</td>
      <td>NaN</td>
      <td>103497.0</td>
      <td>Some-college</td>
      <td>10.0</td>
      <td>Never-married</td>
      <td>NaN</td>
      <td>Own-child</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>48837</th>
      <td>27.0</td>
      <td>Private</td>
      <td>257302.0</td>
      <td>Assoc-acdm</td>
      <td>12.0</td>
      <td>Married-civ-spouse</td>
      <td>Tech-support</td>
      <td>Wife</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>38.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>48838</th>
      <td>40.0</td>
      <td>Private</td>
      <td>154374.0</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Machine-op-inspct</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>48839</th>
      <td>58.0</td>
      <td>Private</td>
      <td>151910.0</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Widowed</td>
      <td>Adm-clerical</td>
      <td>Unmarried</td>
      <td>White</td>
      <td>Female</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>48840</th>
      <td>22.0</td>
      <td>Private</td>
      <td>201490.0</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Never-married</td>
      <td>Adm-clerical</td>
      <td>Own-child</td>
      <td>White</td>
      <td>Male</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>20.0</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>48841</th>
      <td>52.0</td>
      <td>Self-emp-inc</td>
      <td>287927.0</td>
      <td>HS-grad</td>
      <td>9.0</td>
      <td>Married-civ-spouse</td>
      <td>Exec-managerial</td>
      <td>Wife</td>
      <td>White</td>
      <td>Female</td>
      <td>15024.0</td>
      <td>0.0</td>
      <td>40.0</td>
      <td>United-States</td>
      <td>&gt;50K</td>
    </tr>
  </tbody>
</table>
<p>48842 rows × 15 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy metrics from sklearn
from sklearn import metrics

# dictionnary of metrics
metrics_dict={
        &quot;Accuracy&quot;: metrics.accuracy_score,
        &quot;Balanced accuracy&quot;: metrics.balanced_accuracy_score,
        &quot;Precision&quot;: metrics.precision_score,
        &quot;Recall&quot;: metrics.recall_score,
        &quot;F1-Score&quot;: metrics.f1_score}

# efficacy metrics dataframe helper tool
def metrics_dataframe(y_pred, y_true, metrics_dict=metrics_dict):
    metric_list = [[pf, fn(y_true, y_pred)] for pf, fn in metrics_dict.items()]
    return pd.DataFrame(metric_list, columns=[&quot;Metric&quot;, &quot;Value&quot;]).set_index(&quot;Metric&quot;)
</pre></div>
</div>
</div>
</section>
<section id="Baseline">
<h2>Baseline<a class="headerlink" href="#Baseline" title="Permalink to this heading"></a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># sklearn imports
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

# holisticai imports
from holisticai.bias.metrics import classification_bias_metrics
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Implement a Logistic Regression for baseline results

# train
X, y, group_a, group_b = train_data
scaler = StandardScaler()
Xt = scaler.fit_transform(X)
model = LogisticRegression()
model.fit(Xt, y)

# test
X, y, group_a, group_b = test_data
Xt = scaler.transform(X)
y_pred = model.predict(Xt)
y_proba = model.predict_proba(Xt)
y_score = y_proba[:,1]
y_true = y
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Baseline efficacy
metrics_dataframe(y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.850241</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.764963</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.728822</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.600681</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.658576</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>The efficacy assessment shows we can predict salary class with accuracy (0.85). Let’s take a look at bias.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Baseline Bias
classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.178353</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.309067</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.309067</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.457755</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>-0.059581</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.082695</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>-0.071138</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.122388</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>As expected, the results are quite biased, for instance we look at a disparate impact of 0.3. We will show how we can mitigate some of this bias without losing much efficacy.</p>
</section>
<section id="Preprocessing-Strategies">
<h2>Preprocessing Strategies<a class="headerlink" href="#Preprocessing-Strategies" title="Permalink to this heading"></a></h2>
</section>
<section id="Reweighing">
<h2>Reweighing<a class="headerlink" href="#Reweighing" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Kamiran, Faisal, and Toon Calders. “Data preprocessing techniques for classification without discrimination.” Knowledge and information systems 33.1 (2012): 1-33.</p>
<p><a class="reference external" href="https://towardsdatascience.com/reweighing-the-adult-dataset-to-make-it-discrimination-free-44668c9379e8">https://towardsdatascience.com/reweighing-the-adult-dataset-to-make-it-discrimination-free-44668c9379e8</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import
from holisticai.bias.mitigation import Reweighing
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialise
rew = Reweighing()
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit reweighing object to training data
X_train, y_train, group_a, group_b = train_data
rew.fit(y_train, group_a, group_b)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;holisticai.bias.mitigation.preprocessing.reweighing.Reweighing at 0x7fd7d808f6d0&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># access the new sample_weight
sw = rew.estimator_params[&quot;sample_weight&quot;]
sw
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0.85374028, 1.09231797, 0.85374028, ..., 0.78794552, 0.85374028,
       0.78794552])
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Implement a Logistic Regression (with Reweighing)

# train (with reweighing)
X, y, group_a, group_b = train_data
scaler = StandardScaler()
Xt = scaler.fit_transform(X)
model = LogisticRegression()
model.fit(Xt, y, sample_weight=sw) # do not forget to add sample_weight param when fitting!

# test
X, y, group_a, group_b = test_data
Xt = scaler.transform(X)
y_pred = model.predict(Xt)
y_proba = model.predict_proba(Xt)
y_score = y_proba[:,1]
y_true = y
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.843484</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.745096</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.729050</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.555556</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.630587</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias
classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.096208</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.553714</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.553714</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.250423</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.165055</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.030316</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.067370</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.121556</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>The results obtained are better in terms of bias, and efficacy didn’t decrease too much.</p>
</section>
<section id="Learning-Fair-Representations">
<h2>Learning Fair Representations<a class="headerlink" href="#Learning-Fair-Representations" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Zemel, Rich, et al. “Learning fair representations.” International conference on machine learning. PMLR, 2013.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import
from holisticai.bias.mitigation import LearningFairRepresentation
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialise
lfr = LearningFairRepresentation(k=14)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit lfr object to training data (remember to standard scale train data)
X_train, y_train, group_a, group_b = train_data
scaler1 = StandardScaler()
X_train_t = scaler1.fit_transform(X_train)
lfr.fit(X_train_t, y_train, group_a, group_b)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;holisticai.bias.mitigation.preprocessing.learning_fair_representation.LearningFairRepresentation at 0x7fd7d8099460&gt;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># transform train
X_train, y_train, group_a_train, group_b_train = train_data
X_train_t = scaler1.fit_transform(X_train)
new_X_train = lfr.transform(X_train_t, group_a_train, group_b_train)

# transform test
X_test, y_test, group_a_test, group_b_test = test_data
X_test_t = scaler1.fit_transform(X_test)
new_X_test = lfr.transform(X_test_t, group_a_test, group_b_test)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Fit a model with new data (transformed by LFR algorithm)

# train
X, y, group_a, group_b = train_data
X = new_X_train
scaler2 = StandardScaler()
Xt = scaler2.fit_transform(X)
model = LogisticRegression()
model.fit(Xt, y)

# test
X, y, group_a, group_b = test_data
X = new_X_test
Xt = scaler2.transform(X)
y_pred = model.predict(Xt)
y_proba = model.predict_proba(Xt)
y_score = y_proba[:,1]
y_true = y
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.767223</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.558005</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.557427</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.154960</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.242505</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias
classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.008035</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.884467</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.884467</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.032175</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.126363</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.004301</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.061031</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.177722</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>This algorithm has very low recall. It seems fairness is acheived at the expense of efficacy in this case. A good example showing one must be aware of all aspects of the results and not just look at accuracy.</p>
</section>
<section id="Inprocessing-Strategies">
<h2>Inprocessing Strategies<a class="headerlink" href="#Inprocessing-Strategies" title="Permalink to this heading"></a></h2>
</section>
<section id="Grid-Search-Reduction">
<h2>Grid Search Reduction<a class="headerlink" href="#Grid-Search-Reduction" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Agarwal, Alekh, et al. “A reductions approach to fair classification.” International Conference on Machine Learning. PMLR, 2018.</p>
<p>Agarwal, Alekh, Miroslav Dudík, and Zhiwei Steven Wu. “Fair regression: Quantitative definitions and reduction-based algorithms.” International Conference on Machine Learning. PMLR, 2019.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import
from holisticai.bias.mitigation import GridSearchReduction
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># data and model
X, y, group_a, group_b = train_data
scaler = StandardScaler()
Xt = scaler.fit_transform(X)
model = LogisticRegression()
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialize
gsr = GridSearchReduction(constraints=&quot;DemographicParity&quot;)

# incorporate model in gsr
gsr.transform_estimator(model)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchReduction(constraints=&#x27;DemographicParity&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchReduction</label><div class="sk-toggleable__content"><pre>GridSearchReduction(constraints=&#x27;DemographicParity&#x27;)</pre></div></div></div></div></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit with data
gsr.fit(Xt, y, group_a, group_b)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchReduction(constraints=&#x27;DemographicParity&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">GridSearchReduction</label><div class="sk-toggleable__content"><pre>GridSearchReduction(constraints=&#x27;DemographicParity&#x27;)</pre></div></div></div></div></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># predict test
X, y, group_a, group_b = test_data
Xt = scaler.transform(X)
y_pred = gsr.predict(Xt)
y_proba = gsr.predict_proba(Xt)
y_score = y_proba[:,1]
y_true = y
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.829358</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.706411</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.723753</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.469562</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.569584</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias
classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.005191</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.967095</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.967095</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.014306</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.341247</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>0.032478</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.186862</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.113938</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We have solved for equal demographic parity so statistical parity and Disparate Impact are perfect. We lose some recall but overall efficacy is not impacted too much.</p>
</section>
<section id="Exponentiated-Gradient-Reduction">
<h2>Exponentiated Gradient Reduction<a class="headerlink" href="#Exponentiated-Gradient-Reduction" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Agarwal, Alekh, et al. “A reductions approach to fair classification.” International Conference on Machine Learning. PMLR, 2018.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import
from holisticai.bias.mitigation import ExponentiatedGradientReduction
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># data and model
X, y, group_a, group_b = train_data
scaler = StandardScaler()
Xt = scaler.fit_transform(X)
model = LogisticRegression()
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialize
egr = ExponentiatedGradientReduction()

# incorporate model in gsr
egr.transform_estimator(model)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>ExponentiatedGradientReduction(run_linprog_step=(True,))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">ExponentiatedGradientReduction</label><div class="sk-toggleable__content"><pre>ExponentiatedGradientReduction(run_linprog_step=(True,))</pre></div></div></div></div></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit with data
egr.fit(Xt, y, group_a, group_b)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>ExponentiatedGradientReduction(run_linprog_step=(True,))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">ExponentiatedGradientReduction</label><div class="sk-toggleable__content"><pre>ExponentiatedGradientReduction(run_linprog_step=(True,))</pre></div></div></div></div></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># predict test
X, y, group_a, group_b = test_data
Xt = scaler.transform(X)
y_pred = egr.predict(Xt)
y_proba = egr.predict_proba(Xt)
y_score = y_proba[:,1]
y_true = y
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_true)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.836319</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.726850</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.724014</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.515964</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.602535</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias
classification_bias_metrics(group_a, group_b, y_pred, y_true, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.097127</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.523907</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.523907</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.259684</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.037593</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.017864</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.009864</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.101617</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Almost perfect equality of outcome. F1 score is a little bit better than grid search reduction.</p>
</section>
<section id="Postprocessing-Strategies">
<h2>Postprocessing Strategies<a class="headerlink" href="#Postprocessing-Strategies" title="Permalink to this heading"></a></h2>
</section>
<section id="Calibrated-Equalized-Odds-mitigation-technique">
<h2>Calibrated Equalized Odds mitigation technique<a class="headerlink" href="#Calibrated-Equalized-Odds-mitigation-technique" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Pleiss, Geoff, et al. “On fairness and calibration.” Advances in neural information processing systems 30 (2017).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import postprocessing strategy
from holisticai.bias.mitigation import CalibratedEqualizedOdds
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Implement a Logistic Regression for baseline results

# pipeline
pipeline = Pipeline(steps=[
    (&#39;scaler&#39;, StandardScaler()),
    (&#39;classifier&#39;, LogisticRegression()),
    ])

# train
X_train, y_train, group_a_train, group_b_train = train_data
pipeline.fit(X_train, y_train)

# predict train set
y_pred_train = pipeline.predict(X_train)
y_proba_train = pipeline.predict_proba(X_train)

# predict test set
X_test, y_test, group_a_test, group_b_test = test_data
y_pred_test = pipeline.predict(X_test)
y_proba_test = pipeline.predict_proba(X_test)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialize object
ceo = CalibratedEqualizedOdds(cost_constraint=&quot;fnr&quot;)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit it
ceo.fit(y_train, y_proba_train, group_a_train, group_b_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;holisticai.bias.mitigation.postprocessing.calibrated_eq_odds_postprocessing.CalibratedEqualizedOdds at 0x7fd81a9d40a0&gt;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># transform it
d = ceo.transform(y_test, y_proba_test, group_a_test, group_b_test, 0.5)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># new predictions
y_pred = d[&#39;y_pred&#39;]
y_pred
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0, 0, 1, ..., 0, 0, 0])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.831713</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.708107</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.734531</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.469987</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.573209</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias
classification_bias_metrics(group_a_test, group_b_test, y_pred, y_test, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.111584</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.416904</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.416904</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.312611</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.095313</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.054714</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.020299</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.150299</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>It seems this algorithm works best with fnr as an option (on Adult dataset). Both fpr and weighted give bad results.</p>
</section>
<section id="Equalized-Odds-mitigation-technique">
<h2>Equalized Odds mitigation technique<a class="headerlink" href="#Equalized-Odds-mitigation-technique" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Pleiss, Geoff, et al. “On fairness and calibration.” Advances in neural information processing systems 30 (2017).</p>
<p>Hardt, Moritz, Eric Price, and Nati Srebro. “Equality of opportunity in supervised learning.” Advances in neural information processing systems 29 (2016).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Import
from holisticai.bias.mitigation import EqualizedOdds
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[48]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Implement a Logistic Regression for baseline results

# pipeline
pipeline = Pipeline(steps=[
    (&#39;scaler&#39;, StandardScaler()),
    (&#39;classifier&#39;, LogisticRegression()),
    ])

# train
X_train, y_train, group_a_train, group_b_train = train_data
pipeline.fit(X_train, y_train)

# predict train set
y_pred_train = pipeline.predict(X_train)
y_proba_train = pipeline.predict_proba(X_train)

# predict test set
X_test, y_test, group_a_test, group_b_test = test_data
y_pred_test = pipeline.predict(X_test)
y_proba_test = pipeline.predict_proba(X_test)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialize
eq = EqualizedOdds(solver=&#39;highs&#39;, seed=42)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit it
eq.fit(y_train, y_pred_train, group_a_train, group_b_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[50]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;holisticai.bias.mitigation.postprocessing.eq_odds_postprocessing.EqualizedOdds at 0x7fd80ad577f0&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># transform
d = eq.transform(y_pred_test, group_a_test, group_b_test)
d
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[51]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;y_pred&#39;: array([0, 1, 1, ..., 1, 0, 0]),
 &#39;y_score&#39;: array([0., 1., 1., ..., 1., 0., 0.])}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># new predictions
y_pred = d[&#39;y_pred&#39;]
y_pred
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[52]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0, 1, 1, ..., 1, 0, 0])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[53]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.825980</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.733282</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.665815</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.554704</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.605202</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias metrics
classification_bias_metrics(group_a_test, group_b_test, y_pred, y_test, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[54]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.095813</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.587965</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.587965</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.240930</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.020744</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>-0.010227</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.005258</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>0.080495</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Each algorithm will mitigate in slightly different ways. Notice the average odds difference is very low.</p>
</section>
<section id="Reject-Option-Classification">
<h2>Reject Option Classification<a class="headerlink" href="#Reject-Option-Classification" title="Permalink to this heading"></a></h2>
<p>References:</p>
<p>Kamiran, Faisal, Asim Karim, and Xiangliang Zhang. “Decision theory for discrimination-aware classification.” 2012 IEEE 12th International Conference on Data Mining. IEEE, 2012.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># import
from holisticai.bias.mitigation import RejectOptionClassification
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Implement a Logistic Regression for baseline results

# pipeline
pipeline = Pipeline(steps=[
    (&#39;scaler&#39;, StandardScaler()),
    (&#39;classifier&#39;, LogisticRegression()),
    ])

# train
X_train, y_train, group_a_train, group_b_train = train_data
pipeline.fit(X_train, y_train)

# predict train set
y_pred_train = pipeline.predict(X_train)
y_proba_train = pipeline.predict_proba(X_train)

# predict test set
X_test, y_test, group_a_test, group_b_test = test_data
y_pred_test = pipeline.predict(X_test)
y_proba_test = pipeline.predict_proba(X_test)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[57]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># initialize
roc = RejectOptionClassification(metric_name=&quot;Statistical parity difference&quot;)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># fit it
roc.fit(y_train, y_proba_train, group_a_train, group_b_train)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[58]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;holisticai.bias.mitigation.postprocessing.reject_option_classification.RejectOptionClassification at 0x7fd81a63e430&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># transform it
d = roc.transform(y_test, y_proba_test, group_a_test, group_b_test)
d
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[59]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;y_pred&#39;: array([0, 1, 1, ..., 1, 1, 0]),
 &#39;y_score&#39;: array([0.09544274, 0.84811759, 0.61947223, ..., 0.52319612, 0.14669624,
        0.14180466])}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># new predictions
y_pred = d[&#39;y_pred&#39;]
y_pred
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[60]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([0, 1, 1, ..., 1, 1, 0])
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># efficacy
metrics_dataframe(y_pred, y_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[61]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Accuracy</th>
      <td>0.779609</td>
    </tr>
    <tr>
      <th>Balanced accuracy</th>
      <td>0.788730</td>
    </tr>
    <tr>
      <th>Precision</th>
      <td>0.527283</td>
    </tr>
    <tr>
      <th>Recall</th>
      <td>0.806301</td>
    </tr>
    <tr>
      <th>F1-Score</th>
      <td>0.637603</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># bias metrics
classification_bias_metrics(group_a_test, group_b_test, y_pred, y_test, metric_type=&#39;both&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[62]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Value</th>
      <th>Reference</th>
    </tr>
    <tr>
      <th>Metric</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Statistical Parity</th>
      <td>-0.059864</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Disparate Impact</th>
      <td>0.845638</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Four Fifths Rule</th>
      <td>0.845638</td>
      <td>1</td>
    </tr>
    <tr>
      <th>Cohen D</th>
      <td>-0.124368</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Equality of Opportunity Difference</th>
      <td>0.148833</td>
      <td>0</td>
    </tr>
    <tr>
      <th>False Positive Rate Difference</th>
      <td>0.038114</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Average Odds Difference</th>
      <td>0.093473</td>
      <td>0</td>
    </tr>
    <tr>
      <th>Accuracy Difference</th>
      <td>-0.016622</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Great results! We lose some accuracy, but recall increases.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../mitigating_bias.html" class="btn btn-neutral float-left" title="Mitigating bias" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="mitigating_bias_classification_pipeline.html" class="btn btn-neutral float-right" title="Mitigating Bias in Binary Classification with holisticai Pipeline" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Holistic AI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>